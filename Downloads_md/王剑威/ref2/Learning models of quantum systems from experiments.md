# Learning models of quantum systems from experiments

Antonio A. Gentile $^{1,2,10}$ , Brian Flynn $^{1,3,10}$ , Sebastian Knauer $^{1,4,10}$ , Nathan Wiebe $^{5,6}$ , Stefano Paesani $^{1}$ , Christopher E. Granade $^{7}$ , John G. Rarity $^{1}$ , Raffaele Santagati $^{1,8,9,10}$  and Anthony Laing $^{1}$

As Hamiltonian models underpin the study and analysis of physical and chemical processes, it is crucial that they are faithful to the system they represent. However, formulating and testing candidate Hamiltonians for quantum systems from experimental data is difficult, because one cannot directly observe which interactions are present. Here we propose and demonstrate an automated protocol to overcome this challenge by designing an agent that exploits unsupervised machine learning. We first show the capabilities of our approach to infer the correct Hamiltonian when studying a nitrogen-vacancy centre set-up. In preliminary simulations, the exact model is known and is correctly inferred with success rates up to  $59\%$ . When using experimental data,  $74\%$  of protocol instances retrieve models that are deemed plausible. Simulated multi-spin systems, characterized by a space of  $10^{10}$  possible models, are also investigated by incorporating a genetic algorithm in our protocol, which identifies the target model in  $85\%$  of instances. The development of automated agents, capable of formulating and testing modelling hypotheses from limited prior assumptions, represents a fundamental step towards the characterization of large quantum systems.

Distilling models of quantum systems from experimental data in a compact, intelligible form is a core challenge with far-reaching implications $^{1-3}$ . Great strides have been made towards automating the discovery process for learning classical dynamics. In particular, optimal parameterization of models with known structure has been performed, as well as searches for models that exploit nontrivial conservation laws or other basic principles $^{1,4}$ . Other methods invoke innovative neural network architectures for modelling physical systems $^{2,5-8}$ . However, for quantum systems, these methodologies face new challenges, such as the inherent fragility of quantum states and the computational complexity of simulating quantum systems. Tomographic tools have provided a reliable linchpin for this task $^{9,10}$ , but their unfavourable scaling has led to approximate versions in practice $^{11,12}$ . Machine learning methods have recently been applied to learn efficient representations for quantum states $^{13,14}$ , to encode physical parameters $^{6}$ , to perform quantum error correction $^{15,16}$  and to perform sensing $^{17-20}$ . Supervised learning techniques have also been applied to the automated design of quantum gates $^{21}$ , tuning quantum devices $^{22,23}$  and experimental state preparation $^{24}$ . Learning a compact representation for the dynamics of a closed quantum system has also been demonstrated, provided that a Hamiltonian model is known in advance, for example, a parameterized  $\hat{H}_0(\mathbf{x})$ . In the latter case, the optimal  $\mathbf{x}_0$  can be learned via various parameter estimation techniques: Hamiltonian tomography $^{25,26}$ , quantum phase estimation $^{27}$  or quantum Hamiltonian learning (QHL) $^{28-31}$ . However, these protocols necessitate that the user provide the exact form of  $\hat{H}_0$  (refs. $^{32,33}$ ), instead of it being inferred from available data.

We introduce the quantum model learning agent (QMLA) to automatically provide approximate, interpretable Hamiltonian models from experimental data. We describe our protocol as a learning agent because it uses its cumulative knowledge to design informative experiments, as well as generating and comparing new candidate Hamiltonian models to test against experimental evidence, exploiting parameter estimation techniques for the training of individual models. We test QMLA in numerical simulations and apply it to the experimental study of the open-system dynamics of an electron spin in a nitrogen-vacancy (NV) centre in diamond. We show the feasibility of bootstrapping QMLA to study complex systems and larger model spaces, including the spin-bath dynamics of the NV electron spin, where we infer the number of interacting nuclei.

The overarching idea of QMLA is that, to find an approximate model of a system of interest, candidate models are tested against experimental evidence gathered from the system. This is achieved by training individual Hamiltonian models on the data, iteratively constructing new models, and finally selecting the model that best replicates  $\hat{H}_0$ . QMLAs model search occurs across a directed graph (DG) with two components: structural (sDG) and comparative (cDG) (Fig. 1). Each node of the DG represents a single candidate model, for example  $\hat{H}_j$ . The DG is structured in layers, with each layer containing a set  $\mu$  of models (Fig. 1a). For each  $\hat{H}_j(\mathbf{x}) \in \mu$ , a parameter estimation method can optimise  $\mathbf{x}_j'$ , yielding a trained  $\hat{H}_j(\mathbf{x}_j') \equiv \hat{H}_j'(\text{Fig. 1b})$ . In this work, we choose to adopt QHL and in particular the classical likelihood estimation (CLE) protocol[28,34], as sketched in Fig. 1e, adapted for the open system by tracing out the

![](images/d351ce63e504208a417bd8056fed08944c9468c7397cc3bbdf33c83426a17327.jpg)

![](images/ff5fa0d729c2ebb15e4f93e38b57d201fa26a2d960bd1ba16da082044847b065.jpg)

![](images/87edcdf506972864b8486afb1cce845eb86b60c3309b541a2abe8345fbad589a.jpg)

![](images/134f31e32eab059541bd648fde2c019f08ec6c61bfdd394d2d847eb49ee95095.jpg)

![](images/70710068a6117b55c1c5e52995131371d12966ca242d1678c6e0fbf84f85f845.jpg)  
Fig. 1 | Overview of the QMLA protocol and its principal subroutines. a-d, Schematic of a single iteration of a QMLA instance. In a, individual models  $\hat{H}_j$  are held in nodes of an sDG, and models are grouped in layers  $\mu$ . In b, each model  $\hat{H}_j$  within a layer undergoes a parameter estimation stage to optimize the parameterization  $x_j$  against the system Hamiltonian,  $\hat{H}_0$ . In c, within a cDG,  $\mu$  is consolidated, and pairwise Bayes factors  $\mathcal{B}_{i,j}$  are computed for all pairs  $\{\hat{H}_i,\hat{H}_j\} \in \mu$ . A layer champion  $\hat{H}_{\mathbb{C}(\mu)}$  is chosen. In d, through interlayer comparisons, the least performant models are pruned; in particular,  $\hat{H}_{\mathbb{C}(\mu)}$  is compared with its parent. A new layer is spawned from  $\hat{H}_{\mathbb{C}(\mu)}$ . e, Schematic of the Bayesian inference protocol adopted for stage b, that is, to learn an optimal parameterization  $x_j'$ . Following QHL<sup>28</sup>, a (quantum) simulator is invoked as a subroutine for the considered Hamiltonian model. QHL chooses heuristically adaptive evolution times  $t$ , which are used to evolve random input probe states. The same  $|\psi\rangle_{\mathrm{sys}}$  is prepared in both the system and simulator, whereas the uncontrolled initial state of the environment is tentatively chosen as  $|\phi\rangle_{\mathrm{env}}$  for the global system, evolved by the simulator. After tracing out the environmental component ( $t_{\mathrm{env}}$ ), a binary datum  $d$  is collected from projective measurements upon the chosen basis, and used to Bayes-update the estimate of the Hamiltonian parameters. Iterating the sequence leads to the optimized parameterization  $x_i'$ . f, ESs combine the set of previous layer champions,  $\{\hat{H}_{\mathbb{C}(\mu)}\}$ , with the primitives library composed by a finite set of simple Hamiltonians  $\{\hat{h}_1,\hat{h}_2,\dots,\hat{h}_p\}$ , to determine models composing the next layer  $\nu$ .

![](images/60a811b129077293637b3b62b265a30a2a7a8bb785963edf5c53c8dc3525a4b3.jpg)

environmental degrees of freedom from the measurement operation. Alternative Hamiltonian parameter learning algorithms can be exploited without affecting the QMLA procedure.

Once all  $\hat{H}_j \in \mu$  are trained,  $\mu$  is consolidated; that is, the models' performances are evaluated relative to contemporary models. For example, models can be ranked by systematically comparing pairs of models through Bayes factors (BFs), a robust metric to compare the predictive power of different models, while penalizing those with more degrees of freedom[35,36], thus helping to prevent overfitting. The BF comparing  $\hat{H}_i$  against  $\hat{H}_j$  is given by

$$
\mathcal {B} _ {i, j} = \exp \left[ \ell \left(D _ {i j} \mid \hat {H} _ {i}\right) - \ell \left(D _ {i j} \mid \hat {H} _ {j}\right) \right], \tag {1}
$$

where  $D_{i(j)}$  is the cumulative dataset of all experimental outcomes  $\{d\}$  used during the training of model  $\hat{H}_i(\hat{H}_j)$  (Fig. 1e),  $D_{ij} = D_i \cup D_j$  is the joint dataset and  $\ell(D_{ij}|\hat{H}_j) = \sum_{d \in D_{ij}} \log \mathcal{L}(d|\hat{H}_j, \mathbf{x}_j, |\psi\rangle, t)$  is the cumulative log-likelihood<sup>37</sup>. The comparisons are stored in the cDG (Fig. 1c) and allow for the selection of (one or more) layer champion(s),  $\hat{H}_{\mathrm{C}(\mu)}$ , that is, the model(s) within  $\mu$  that best reproduces the dynamics of  $\hat{H}_0$ . Crucially, other models within  $\mu$  are then deactivated (that is, pruned from the sDG), and  $\hat{H}_{\mathrm{C}(\mu)}$  is compared with its parent.

An exploration phase follows, whereby a new set of models is generated according to an exploration strategy (ES). These are placed on the next layer of the DG,  $\nu$ , and are considered children to the model(s) from which they spawned, as depicted in Fig. 1f via directed edges in the sDG. Various ESs used in this work are discussed in the Methods; however, they all rely on a core

inheritance principle: spawned models inherit some or all of the terms of their parent, adding further terms as deemed appropriate by the ES, for example, greedily adding single terms from a set of primitives. Children models are likely to stem from relatively strong models on the previous layer, such that the average approximation of  $\hat{H}_0$  tends to improve with each new layer. The procedure iterates until some predetermined criteria indicate that the search should terminate (Methods). Following the termination of the exploration phase, the set of surviving layer champions  $\mathbb{H}_{\mathbb{C}}$  is consolidated to select the global champion model,  $\hat{H}^{\prime}$ .  $\hat{H}^{\prime}$  is the model that QMLA determines as the optimal approximation of the target system. Together, the set of primitive terms, ESs and termination criteria determine the flexibility of QMLA, which can be tuned by the user to exploit any prior knowledge about the system.

We applied QMLA to the experimental study of the dynamics of an NV centre electron spin in diamond that is interacting with the surrounding nuclei of its spin bath. The (expected) complete Hamiltonian model  $\hat{H}_{\mathrm{full}}$  for this system is reported and discussed in the Methods, equations (3a) and (3b). To be effective, evaluating which terms are meaningful in  $\hat{H}_{\mathrm{full}}$  must go beyond a mere parameter estimation, as the various parameters involved in it span several orders of magnitude[38,39]. Therefore, choosing to neglect some of them according solely to their magnitude would be arbitrary. The experiment design has two main controls (Fig. 1e): the evolution time  $t$  for the system of study[34] and the initial quantum state of the electron spin (the probe state,  $|\psi \rangle_{\mathrm{sys}}$ ). We extract data from the system using Hahn-echo sequences (Fig. 2a): these start preparing  $|\psi \rangle_{\mathrm{sys}} \equiv | + \rangle$ , and interrupt a free spin evolution after  $t$ , to

![](images/7f8874c28164312170eeefe0bc48ef591118ab0f8586f07cc5f9a25ba0475dab.jpg)  
a

![](images/fa6bb930af357347705f8b32274195bc0df2cfef62e58715dba7d00010d19658.jpg)  
b

![](images/f409375bcde0dfda548263695458f0dbfd6a04e480bff4ef2269d852221dbd25.jpg)  
c

![](images/083d8550a2e496db9a05fe6b6d7cdd5f94ae63976fbcb90a147ff31b64788697.jpg)  
d

![](images/6f4ec9f929fa06a450b89c6f632dd0c9cf427ea16d77bfd36ebbe61525efcbd9.jpg)  
e  
Fig. 2 | QMLA results for simulated and experimental data, describing a NV centre system. a, Left: the carbon lattice (black spheres) providing the outer environment for the NV centre (the N atom is shown in yellow and and the vacancy in faint green). Thin black lines highlight the unit cell. Right: the evolution of the electron spin state is represented on a Bloch sphere: the initial  $\pi /2$  and intermediate Hahn-echo  $(\pi)$  microwave pulses are in blue, and the free precession before (after) application of the Hahn control pulse, for a time  $t(t')$ , is in red. The final  $\pi /2$  pulse at the end of the sequence is omitted. b, Simulation of 500 independent QMLA instances, where  $\hat{H}_0$  is chosen randomly. The win rate is reported against the difference  $(N_p - N_p')$  between the number of parameters in the QMLA-selected  $(\hat{H}')$  and true models, respectively. The under-parameterized (over-parameterized) class refers to models with fewer (more) parameters than  $\hat{H}_0$ . 'Correct' indicates that exactly  $\hat{H}_0$  was found. The mis-parameterized class groups models with the same parameter cardinality as  $\hat{H}_0$ , but different Hamiltonian terms. Inset: histogram of occurrences of the coefficient of determination  $(R^2)$  values for each retrieved  $\hat{H}'$  against a sampling of data points from  $\hat{H}_0$ , with median  $R^2 = 0.84$  (red dotted line). The blue line separates occurrences with  $R^2 < 0$ . c, Win rates of the top four models (see text) for 100 QMLA instances, against both simulated and experimental data. For experimental data,  $\hat{H}_0$  is unknown, while simulations use  $\hat{H}_0 = \hat{S}_{x,y,z}\hat{A}_z$ . d, Total volume spanned by the parameters' prior across epochs, for the models in c. The shaded areas show the  $67\%$  confidence region of volumes from instances where those models were deemed  $\hat{H}'$ . e, Simulated likelihoods reproduced by the model with the highest win rate  $(\hat{S}_{x,y,z}\hat{A}_z,$  turquoise), compared with the corresponding NV-centre-system experimental data (red dots, extracted from the observed photoluminescence of the first microseconds in the Hahn-echo decay). Error bars for the experimental data are smaller than the symbols (Methods); the shaded area indicates the  $67\%$  confidence region of likelihoods predicted from the instances where  $\hat{S}_{x,y,z}\hat{A}_z$  was deemed  $\hat{H}'$ . f, A single QMLA instance against the experimental data in e, depicted as a cDG (Fig. 1c). The thin end of each edge points to the favoured model, and the colour of the edges depicts the strength of evidence,  $\log_{10}B$ . Champions of each layer,  $\hat{H}_{C(\mu)}'$ , are in light brown, whereas the global champion  $\hat{H}'$  is in orange and all other models are reported as grey circles. Further details about the simulations are provided in the Methods.

![](images/74c4274c6c47072ba64f46426dafaf35fc480042bdb4f01f51301c0192366b4b.jpg)  
f

apply a Hahn angle. After a further time  $t'$ , information about the evolved state is collected using a standard confocal set-up, collecting the photoluminescence signal from the NV centre, proportional to the likelihood of finding the electron spin in the ground state,  $\mathcal{L}(0|\dot{H}_0,t,|\psi \rangle_{\mathrm{sys}})$ . More details on the experimental set-up are provided in the Methods and Supplementary section 3A.

Echo sequences attempt to decouple the electron spin dynamics from the nuclear bath $^{40,41}$ , making it an ideal study case where QMLA can learn residual contributions from the environment. In a first test, we attempt to learn a model from the short decay, obtained when  $t \neq t'$ . In this instance, where the signal decays in a few microseconds (Fig. 2e), we can assume a static bath, and in

a simplified open system picture, encode the entire spin environment in a single, effective qubit $^{42}$ . The remaining contributions can be introduced hierarchically in an immediately interpretable sDG, as detailed in the Methods. Each layer here exhibits models characterized by the same Hilbert space dimension, and number of parameters, and these increase with the graph depth. Therefore, this ES spawns new models deterministically from a single parent champion. It is then reasonable to compare adjacent layers via their champions. For example, if the parent is strongly outperformed by its child  $(\mathcal{B}_{C(\nu),C(\mu)} \gg 1)$ , the protocol deactivates the entire layer on which the parent resides (the collapse rule depicted in Fig. 1d).

In a compact symbolic form, we can write the Hamiltonian

$$
\hat {H} _ {\text {f a s t}} \approx \hat {S} _ {x, y, z} + \hat {A} _ {x, y, z} + \hat {T} _ {x y, x z, y z}, \tag {2}
$$

where  $\hat{S}_{x,y,z} = \sum_{i\in \{x,y,z\}}\alpha_i\hat{\sigma}_i$  are the spin rotation terms, whereas  $\hat{A}_{x,y,z} = \sum_{j\in \{x,y,z\}}\beta_j(\hat{\sigma}_j\otimes \hat{\sigma}_j)$  are the diagonal and  $\hat{T}_{kl} = \sum_{k,l\neq k\in \{x,y,z\}}\gamma_{kl}\hat{\sigma}_k\otimes \hat{\sigma}_l$  the transverse hyperfine contributions. Our primitives are thus the Pauli matrices  $\{\hat{\sigma}_i\}$ . In this compact representation,  $\{\alpha ,\beta ,\gamma \}$  represent the parameters to be learned in the training stage of QMLA (Fig. 1b).

To assess QMLA's performance we run tests for three distinct cases:

(1) Data from a simulated system, where  $\hat{H}_0$  is composed by an arbitrary subset of terms from equation (2), while allowing QMLA to prepare arbitrary probe states;  
(2) Data from a simulated system mimicking our experimental set-up, that is, choosing  $\hat{H}_0 = \hat{S}_{xyz}\hat{A}_z$  and

$$
| \psi \rangle = | + + ^ {\prime} \rangle = | + \rangle \frac {| 0 \rangle + e ^ {i \varphi} | 1 \rangle}{\sqrt {2}} (w i t h \varphi r a n d o m);
$$

(3) Experimental data obtained from the NV centre preparing  $|\psi \rangle \approx | + + ^{\prime}\rangle$  , where  $\hat{H}_0$  is unknown.

We first run 500 independent QMLA instances against data as in case 1. In Fig. 2b we report the cumulative win rate, that is, the percentage of times a model has been selected, as a function of the difference between the number of parameters in the known correct  $\hat{H}_0(\mathbf{x}_0)$ ,  $N_p$ , and that of the champion model for each instance,  $N_p'$ . Defining the success rate (SR) as the fraction of QMLA instances for which the correct (known) model is deemed champion, we observe SR = 50 ± 0.5%. The winning models show similar performance with respect to predictive power, with median  $R^2 = 0.84$  across all instances (inset, Fig. 2b). For the simulations of case 2, we restrict the accessible probe states to reflect the experimental limitations. In this case, SR = 59%. Moreover, according to Fig. 2c, this success rate rises to 88% when we extend the acceptable solutions to include any of five additional models, which are known to well approximate  $\hat{H}_{\mathrm{fast}}$  in typical set-ups. We term this set of models 'credible', and report the full list in the Methods.

Finally, for case 3, QMLA is tested against the experimental data from Fig. 2e. Here the underlying model is unknown, but equation (2) is expected to include all terms necessary for a thorough model, with several of them usually neglected[30,43,44]. In this case, credible models are found in  $74\%$  of the QMLA instances run (Fig. 2c), with one of the simplest approximations,  $\hat{S}_{x,y,z}\hat{A}_z$ , occurring in  $46\%$  of the cases. For each candidate's parameterization and after each training epoch, an estimate of the width of the posterior distribution is given by the volume of the particles  $\{\mathbf{x}_i\}$  entertained as a discretization of the parameters' space. In Fig. 2d, we observe said volume (exponentially) decrease for the top four models, a sign of successful convergence of the training, as detailed in Supplementary section

1C. Figure 2e compares  $\mathcal{L}\left(0\mid \hat{H}^{\prime}(\mathbf{x}^{\prime}),|\psi \rangle_{\mathrm{sys}},t\right)$  extracted from the most successful model  $\hat{H}^{\prime}$ , against the normalized photoluminescence from the experimental set-up: the two are in excellent agreement, with median  $R^2 = 0.82$ . We exemplify a cDG used by QMLA for the model search from experimental data in Fig. 2f, where increasingly complex models are generated up to  $\hat{S}_{x,y,z}A_{x,y,z}\hat{T}_{xy,xz,yz}$ .

The analysis, so far, has targeted a minimal model to explain the rapid dynamics of the fast decay. In such cases, the mapping to a single environmental qubit provides an excellent approximation (such as in Fig. 2e), whereas the effects of a finite-size bath consisting of  $n^s$  spins are expected to be evident at the longer times probed by Hahn-echo experiments[41]. Next, we investigate whether QMLA can be used to conduct an in-depth study of the bath, even in the absence of full control/measurement over the environmental

degrees of freedom. To do so, we need to simulate larger systems, leading to a larger number of potential interactions. The ESs previously shown for the short decay allow for an immediate interpretation of the DG obtained (for example, in Fig. 2f), but restrict the searchable model space. We test the potential of QMLA to autonomously structure the model search, by incorporating a genetic algorithm (GA) within an ES.

Individual models are thought of as chromosomes, with generations progressively filling the layers of the sDG. Models are mapped to binary bit strings (the GA's chromosomes), with each bit representing a single Hamiltonian term. The GA generalizes the inheritance principle by constructing new candidate models that inherit terms from two parents, chosen by QMLA from the pool of best-performing models in the previous generation. This implementation can be considered a special case of the general framework introduced in Fig. 1, as discussed in the Methods.

Specifically for the tests reported here, we independently entertain all the potential 33 Hamiltonian terms stemming from the complete Hamiltonian model (equations (3a) and (3b) in the Methods), coupling up to  $|\chi| = 5$  nuclear sites, when the zero-field and quadrupole splittings are neglected, and a diagonal hyperfine term is invoked. Further details for the GA design and implementation are provided in the Methods. This choice leads to QMLA operating in a space of  $2^{33} \approx 10^{10}$  models. The outcome of this adaptive model search across this large space is summarized by Fig. 3a-d. First we show that, for a single QMLA instance, the approximation to  $\hat{H}_0$  provided by candidate  $\hat{H}_j$  tends to improve as generations progress. We capture this with the  $F_1$  score,  $\mathcal{F} \in [0,1]$ , reported in Fig. 3a, where  $\mathcal{F}$  is an indicator of how many terms of  $\hat{H}_j$  overlap with  $\hat{H}_0$ ; for example,  $\mathcal{F}_j = 0$  if  $\hat{H}_j$  shares no terms with  $\hat{H}_0$  and  $\mathcal{F}_j = 1$  uniquely for  $\hat{H}_i = \hat{H}_0$ . The quality of the approximation is also exemplified for selected generations in Fig. 3b, where we display how the true dynamics of the system are predicted with increasing accuracy by successive generation champions. Typical performances of QMLA exploiting a GA are then tested. Cumulative outcomes of 100 independent instances are shown in Fig. 3c,d. The first shows how candidates from the total model space are normally distributed around  $\bar{\mathcal{F}} \approx 0.44$ , whereas QMLA quickly moves to a high-quality subspace, and ultimately nominates the true model as champion in  $85\%$  of cases. In a single QMLA instance, roughly 1,000 models are evaluated before isolating  $\hat{H}_0$ , providing a huge advantage against a brute-force search involving all  $10^{10}$  possible models. Observing the frequency with which Hamiltonian terms are found within nominated champions in Fig. 3d, we see that QMLA can consistently distinguish interactions that contribute to  $\hat{H}_0$ 's dynamics, allowing for its complete characterization.

By using a GA, we have emphasized the possibility for QMLA to autonomously explore the model space within a user-specified range (for example, up to six qubits in Fig. 3a-d), corresponding to a guess for the global system dimension. The lower end of this range might be provided by dimensional witnesses $^{45}$ , whereas retrieving a sensible upper limit is an important but nontrivial task. In the absence of a trusted quantum simulator of appropriate size, evolving large-scale quantum systems with classical simulators rapidly becomes impractical. It is hence desirable to bootstrap QMLA to avoid evaluating candidate models beyond a sufficient dimension, instead of discarding them upon a triggered termination condition. Here, we exemplify such a bootstrap by leveraging on the mechanics of QHL. The simulator ultimately provides estimates for the likelihood  $\mathcal{L}(d|\mathbf{x}_i,t)$ : if the likelihood can be expressed via a compact (albeit approximate) analytical function, a classical simulator can estimate it for quantum systems of large size.

This strategy can be applied to the system under study, because the interaction of the NV centre with the bath can be modelled in terms of effective beating frequencies, as far as the secular approximation and a well-aligned external magnetic field can be invoked<sup>40</sup>.

![](images/44e0b222bc019a95f8e840f46bccf3075ff520f7ed2408931943129311a8b668.jpg)  
a

![](images/bc684894ae07bb9e75883051524e54e6d286b4c86110ba0d3fa32fcef78ba04f.jpg)  
c

![](images/cd00a47faddc25b7b10349435ed821cca38408d0b39cc39f7089571389f2047c.jpg)  
e

![](images/37df6baa60b7f1bdd46b1f6d255996283be87e3e0fe51bf66f3fc4e286ef96b7.jpg)  
b  
Fig. 3 | QMLA applied to systems composed of several interacting spins implementing various exploration strategies. a–d, QMLA with genetic ES. a, Evolution of the  $F_{1}$  score ( $\mathcal{F}$ ) for active models at each generation (QMLA layer). b, Predicted likelihood by generation champions (dashed curves) against data for the simulated  $\hat{H}_{0}$  (red dots), showing the improvement of predictive power as the GA improves the modelling of  $\hat{H}_{0}$ . c, Distribution of  $\mathcal{F}$  as normalized histograms, for a Monte-Carlo sample of  $10^{6}$  models from the total available model space (green), all models entertained across 100 independent QMLA instances (blue) and only the champion models  $\hat{H}'$  selected therein, upon convergence (pink). d, Hinton diagram, where the size of the tiles indicates the frequency with which each Hamiltonian term is found in  $\hat{H}'$  by QMLA, out of 100 independent instances. Models entertain up to five nuclear sites (labelled as 1-5), along with the electron spin ( $e^{-}$ ). For brevity, we adopt the notation  $\hat{l}_{e^{-}} \equiv \hat{S}$ . Green (blue) tiles indicate the term is (not) in  $\hat{H}_{0}$ , and circles identify inconsistent labels, that is, terms that were not considered by QMLA. e,f, Analysis of experimental baths embedding a number of spins  $n^{s} \gg 1$ . In e, the outcome of MHA sampling from a distribution  $P(n^{s})$  proportional to the absolute log-likelihood  $|\ell(n^{s})|$  is shown. Exemplary samplings for  $P(n^{s})$  out of a single MHA run up to 10,000 steps are displayed. Inset: detail of the distribution behaviour for  $n^{s} \leq 20$ . A dash-dotted black line indicates the fit of the logistic mock function to the output sample from MHA. f, Normalized photoluminescence signal for Hahn-echo experiments, against evolution time  $\tau = \tau'$ . Red dots represent experimental data (error bars are omitted as they are smaller than the dots), while the green line is the expected photoluminescence obtained from the model with  $n^{s} = 20$ , whose parameters are the average outcome of running QHL independently 100 times. Estimates from fits for the decoherence time  $T_{2}$  obtained from experimental data, and QHL, are also reported.

![](images/06e82fe5d0f2ba0cef8d94d2fceabe34760809dc5d4d3877c9035bb7ca27cf33.jpg)  
d

![](images/b2a48f9349240f33de1d0c9ba11c6591877747d32e0ec4e17ad6b24e98552090.jpg)  
f

Using an appropriate hyperparameterization of the resulting analytical  $\mathcal{L}$  to render the parameter learning efficient $^{37,46}$ , we could explore models of size up to  $n^s \approx 100$  environmental qubits, at the cost of fixing the terms implicitly included in each candidate  $\hat{H}_i$ . This amounts to QMLA building an sDG that is effectively a chain of models, with increasing dimension, where we expect parent-child comparisons to exhibit  $\mathcal{B}_{ij} \approx 1$  (hence be non-significative) once enough nuclear spins have been included in the bath. We choose to display this via the probability distribution  $P(n^s)$  obtained via a Metropolis-Hastings algorithm (MHA), whereby, at each step of the algorithm, an  $n^s$  is sampled, and a trial form of the analytical likelihood is trained via CLE. The sample acceptance depends on the value of the cumulative log-likelihood  $\ell(D|n^s)$ . Further details about this procedure are provided in the Methods.

In Fig. 3e we show the MHA outcome after up to 10,000 steps. In the inset, we emphasize how the approximated distribution starts to plateau for  $n^s \approx 13$ , so that, for this system, there is no compelling evidence to consider many additional spins in the bath. Interestingly, our estimate is well below the number of nuclear sites employed in initial simulations of Hahn-echo experiments with NV centres $^{41}$ , but agrees in order of magnitude with the number of  $^{13}\mathrm{C}$  in the first shell, known to be hyperpolarizable $^{30,47}$ . Finally, we show in Fig. 3f the expected normalized photoluminescence signal, estimated via CLE from the same hyperparameterized model, with  $n^s = 20$ , together with experimental data. Simulated photoluminescence accurately reproduces the experimental findings, including the revival peak positions, allowing an independent estimate of the

decoherence time for this system, from the envelope of the revived photoluminescence signals:  $T_{2} = 81 \pm 3.9 \mu \mathrm{s}$ .

QMLA combines the advantages of an automated search with leveraging the user's prior knowledge. The former can focus on a subspace of all possible models, outputting graph searches of immediate interpretability to provide unique insights into the system's physics. At the same time, QMLA can be adapted to embed, or retrieve, different information. In particular, we have shown that approximate theoretical models can be used to bootstrap further searches, while relaxing the ES to a genetic approach allows, with only limited resources, effectively searching through the vast model spaces expected from a blackbox description of a device. QMLA allows for a number of improvements over alternative model recovery strategies. First, we consider methods that optimize the parameters  $\mathbf{x}$ , when given a Hamiltonian  $\hat{H}_0 = \sum_i x_i \hat{h}_i$ . Such a parameterized decomposition in primitives  $\{\hat{h}_i\}$  may derive from intuition about the system as in QHL[28] or Hamiltonian tomography[48], knowledge of the eigenstates[49], or be a generic basis of operators for the corresponding Hilbert space[50,51]. These methods all provide possible implementations for the parameter learning subroutine within QMLA (that is, Fig. 1b), but do not exhaust QMLA's capabilities. By trusting a presumed Hamiltonian model, they are prone to under- or over-fit the system's description, without offering an embedded, statistically motivated test to overcome these inaccuracies.

On the contrary, techniques such as quantum process tomography (QPT), which make very few assumptions about the system,

usually rely on informationally complete sets of experiments. Standard QPT ensures a thorough description of the quantum channel as a map  $\mathcal{M}$ , but at the cost of exponential scaling, with the system's dimension  $n$ , of the measurement settings required by QPT  $(16^{n})$ . Likewise, gate set tomography (GST) reconstructs the whole gate set operating upon non-calibrated input states, thus addressing a crucial experimental cost[52], at the cost of introducing Markovianity assumptions about the system. Unfavourable scaling, coupled with the associated classical post-processing, has limited the application of QPT to three-qubit systems, unless resorting again to a known structure[53]. Moreover, the information extracted by any tomographic method assumes non-accessible dynamics, apart from the final output state. This need not be the case for systems and devices where, for example, the duration of interactions among constituent components within the system, or with the environment, can be accurately controlled experimentally, such as the NV centre studied here.

In such cases, we argue that a complete characterization of the system at a single point in time,  $t$ , is not conclusive of the system's evolution for general  $t' \neq t$ . In principle, one might assume  $\mathcal{M}$  to simply be the exponentiated  $\hat{H}$ , thus recovering  $\hat{H}' = i\log (\mathcal{M}) / t$ . Beside the non-uniqueness of the matrix logarithm, this classical post-processing is expensive to scale, as it requires the eigenvectors of  $\mathcal{M}$  to be known. These caveats contribute to the already prohibitive scaling of full QPT. Resorting instead to approximate tomographic methods can lead to the infidelity of model reconstructions being amplified by the logarithm extraction. Finally, the effects of different terms can strongly depend on  $t$ , as is visible already in this NV centre study case. The user should then ideally repeat the tomography for several evolutions of  $t$  in the range of interest, down to intervals ultimately controlled by  $\hat{H}_0$ 's eigenvalues. QMLA, instead, directly targets the generator of the dynamics and manages the intricacies of controlling the evolution time. In conclusion, our protocol bridges the gap between existing methods for the efficient characterization of trusted Hamiltonian models, and expensive tomographic methods. The prior information requested by QMLA is similar to that for tomographic approaches: exploration strategies can be tailored by the user equivalently to gauge optimization and terms in GST<sup>52</sup>.

In the context of quantum technologies, QMLA could be used to improve our knowledge of decoherence processes and design adaptive methodologies to counteract them[54]. To efficiently tackle more complex environments and decoherence effects, we envisage that future work will extend QMLA to address open systems, exploiting alternative descriptions, such as Lindblad operators[55]. In practice, we envisage that QMLA may help in diagnosing imperfect experimental protocols and devices, aiding engineering efforts towards reliable quantum technologies, as well as empowering noisy intermediate-scale quantum devices as a tool to deepen our understanding of novel quantum systems.

# Online content

Any methods, additional references, Nature Research reporting summaries, source data, extended data, supplementary information, acknowledgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/s41567-021-01201-7.

Received: 30 January 2020; Accepted: 10 February 2021

Published online: 29 April 2021

# References

1. Schmidt, M. & Lipson, H. Distilling free-form natural laws from experimental data. Science 324, 81-85 (2009).  
2. Carleo, G. et al. Machine learning and the physical sciences. Rev. Mod. Phys. 91, 045002 (2019).

3. Poulsen Nautrup, H. et al. Operationally meaningful representations of physical systems in neural networks. Preprint at https://arxiv.org/pdf/2001.00593.pdf (2020).  
4. Hills, D. J., Grütter, A. M. & Hudson, J. J. An algorithm for discovering Lagrangians automatically from data. PeerJ Comput. Sci. 1, e31 (2015).  
5. Carrasquilla, J. & Melko, R. G. Machine learning phases of matter. Nat. Phys. 13, 431-434 (2017).  
6. Iten, R., Metger, T., Wilming, H., Delrio, L. & Renner, R. Discovering physical concepts with neural networks. Phys. Rev. Lett. 124, 010508 (2020).  
7. Greydanus, S., Dzamba, M. & Yosinski, J. Hamiltonian Neural Networks (Curran Associates, 2019).  
8. Flurin, E., Martin, L. S., Hacohen-Gourgy, S. & Siddiqi, I. Using a recurrent neural network to reconstruct quantum dynamics of a superconducting qubit from physical observations. Phys. Rev. X 10, 011006 (2020).  
9. Mohseni, M., Rezakhani, A. T. & Lidar, D. A. Quantum-process tomography: resource analysis of different strategies. Phys. Rev. A 77, 032322 (2008).  
10. Spagnolo, N. et al. Learning an unknown transformation via a genetic approach. Sci. Rep. 7, 14316 (2017).  
11. Lanyon, B. P. et al. Efficient tomography of a quantum many-body system. Nat. Phys. 13, 1158-1162 (2017).  
12. Huang, H.-Y., Kueng, R. & Preskill, J. Predicting many properties of a quantum system from very few measurements. Nat. Phys. 16, 1050-1057 (2020).  
13. Carleo, G. & Troyer, M. Solving the quantum many-body problem with artificial neural networks. Science 355, 602-606 (2017).  
14. Dunjko, V. & Briegel, H. J. Machine learning and artificial intelligence in the quantum domain: a review of recent progress. Rep. Prog. Phys. 81, 074001 (2018).  
15. Fösel, T., Tighineanu, P., Weiss, T. & Marquardt, F. Reinforcement learning with neural networks for quantum feedback. Phys. Rev. X 8, 031084 (2018).  
16. Poulsen Nautrup, H., Delfosse, N., Dunjko, V., Briegel, H. J. & Friis, N. Optimizing quantum error correction codes with reinforcement learning. Quantum 3, 215 (2019).  
17. Santagati, R. et al. Magnetic-field learning using a single electronic spin in diamond with one-photon readout at room temperature. Phys. Rev. X 9, 021019 (2019).  
18. Lumino, A. et al. Experimental phase estimation enhanced by machine learning. Phys. Rev. Appl. 10, 044033 (2018).  
19. Aharon, N. et al. NV center based nano-NMR enhanced by deep learning. Sci. Rep. 9, 17802 (2019).  
20. Liu, G., Chen, M., Liu, Y-X., Layden, D. & Cappellaro, P. Repetitive readout enhanced by machine learning. Mach. Learn. Sci. Technol. 1, 015003 (2020).  
21. Banchi, L., Pancotti, N. & Bose, S. Quantum gate learning in qubit networks: Toffoli gate without time-dependent control. npj Quantum Inf. 2, 16019 (2016).  
22. Stenberg, M. P. V., Kohn, O. & Wilhelm, F. K. Characterization of decohering quantum systems: machine learning approach. Phys. Rev. A 93, 012122 (2016).  
23. Darulova, J. et al. Autonomous tuning and charge-state detection of gate-defined quantum dots. Phys. Rev. Appl. 13, 054005 (2020).  
24. Krenn, M., Malik, M., Fickler, R., Lapkiewicz, R. & Zeilinger, A. Automated search for new quantum experiments. Phys. Rev. Lett. 116, 090405 (2016).  
25. DiFranco, C., Paternostro, M. & Kim, M. S. Hamiltonian tomography in an access-limited setting without state initialization. Phys. Rev. Lett. 102, 187203 (2009).  
26. Schirmer, S. G. & Oi, D. K. L. Two-qubit Hamiltonian tomography by Bayesian analysis of noisy data. Phys. Rev. A 80, 022333 (2009).  
27. Seveso, L. & Paris, M. G. A. Estimation of general Hamiltonian parameters via controlled energy measurements. Phys. Rev. A 98, 032114 (2018).  
28. Wiebe, N., Granade, C., Ferrie, C. & Cory, D. G. Hamiltonian learning and certification using quantum resources. Phys. Rev. Lett. 112, 190501 (2014).  
29. Evans, T., Harper, R. & Flammina, S. Scalable Bayesian Hamiltonian learning. Preprint at https://arxiv.org/pdf/1912.07636.pdf (2019).  
30. Hou, P.-Y. et al. Experimental Hamiltonian learning of an 11-qubit solid-state quantum spin register. Chin. Phys. Lett. 36, 10030 (2019).  
31. Valenti, A., Vannieuwenburg, E., Huber, S. & Greplova, E. Hamiltonian learning for quantum error correction. Phys. Rev. Res. 1, 033092 (2019).  
32. Hincks, I., Granade, C. & Cory, D. G. Statistical inference with quantum measurements: methodologies for nitrogen vacancy centers in diamond. New J. Phys. 20, 013022 (2018).  
33. Wang, J. et al. Experimental quantum Hamiltonian learning. Nat. Phys. 13, 551-555 (2017).  
34. Granade, C. E., Ferrie, C., Wiebe, N. & Cory, D. G. Robust online Hamiltonian learning. New J. Phys. 14, 103013 (2012).  
35. Kass, R. E. & Raftery, A. E. Bayes factors. J. Am. Stat. Assoc. 90, 773-795 (1995).  
36. Myung, I. J. Applying Occam's razor in modeling cognition: a Bayesian approach. Psychon. Bull. Rev. 4, 79-95 (1997).

37. Granade, C. et al. QInfer: statistical inference software for quantum applications. Quantum 1, 5 (2017).  
38. Smeltzer, B., Childress, L. & Gali, A.  $^{13}\mathrm{C}$  hyperfine interactions in the nitrogen-vacancy centre in diamond. New J. Phys. 13, 025021 (2011).  
39. Kalb, N., Humphreys, P. C., Slim, J. J. & Hanson, R. Dephasing mechanisms of diamond-based nuclear-spin memories for quantum networks. Phys. Rev. A 97, 062330 (2018).  
40. Rowan, L. G., Hahn, E. L. & Mims, W. B. Electron-spin-echo envelope modulation. Phys. Rev. 137, A61-A71 (1965).  
41. Childress, L. et al. Coherent dynamics of coupled electron and nuclear spin qubits in diamond. Science 314, 281-285 (2006).  
42. Sweke, R., Sinayskiy, I. & Petruccione, F. Simulation of single-qubit open quantum systems. Phys. Rev. A 90, 022331 (2014).  
43. Gali, A., Fyta, M. & Kaxiras, E. Ab initio supercell calculations on nitrogen-vacancy center in diamond: electronic structure and hyperfine tensors. Phys. Rev. B 77, 155206 (2008).  
44. Gurudev, D. M. V. et al. Quantum register based on individual electronic and nuclear spin qubits in diamond. Science 316, 1312-1316 (2007).  
45. Brunner, N., Navascués, M. & Vertesi, T. Dimension witnesses and quantum state discrimination. Phys. Rev. Lett. 110, 150501 (2013).  
46. Granade, C. & Wiebe, N. Structured filtering. New J. Phys. 19, 083014 (2017).  
47. Alvarez, G. A. et al. Local and bulk  $^{13}\mathrm{C}$  hyperpolarization in nitrogen-vacancy-centred diamonds at variable fields and orientations. Nat. Commun. 6, 8456 (2015).

48. Li, Z., Zou, L. & Hsieh, T. H. Hamiltonian tomography via quantum quench. Phys. Rev. Lett. 124, 160502 (2020).  
49. Chertkov, E. & Clark, B. K. Computational inverse method for constructing spaces of quantum models from wave functions. Phys. Rev. X 8, 031029 (2018).  
50. Shabani, A., Mohseni, M., Lloyd, S., Kosut, R. L. & Rabitz, H. Estimation of many-body quantum Hamiltonians via compressive sensing. Phys. Rev. A 84, 012107 (2011).  
51. Bairey, E., Arad, I. & Lindner, N. H. Learning a local Hamiltonian from local measurements. Phys. Rev. Lett. 122, 020504 (2019).  
52. Nielsen, E. et al. Gate set tomography. Preprint at https://arxiv.org/pdf/2009.07301.pdf (2020).  
53. Torlai, G. et al. Quantum process tomography with unsupervised learning and tensor networks. Preprint at https://arxiv.org/pdf/2006.02424.pdf (2020).  
54. Scerri, E., Gauger, E. M. & Bonato, C. Extending qubit coherence by adaptive quantum environment learning. New J. Phys. 22, 035002 (2020).  
55. Reiter, F. & Sørensen, A. S. Effective operator formalism for open quantum systems. Phys. Rev. A 85, 032111 (2012).

Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

© The Author(s), under exclusive licence to Springer Nature Limited 2021

# Methods

QMLA architecture. The training of each candidate model  $\hat{H}_j$  requires a parameter learning subroutine to be embedded in QMLA. Here, we chose to adopt QHL, which encodes the information about each parameter in a discretized distribution  $P(\mathbf{x}_j)$  of  $N_P$  particles, and updates  $P(\mathbf{x}_j)$  via Bayesian inference[17,28,33]. Our preference is motivated by the promise of QHL's enhancement through the availability of quantum simulators, envisioned in refs.[28,33]. The uncertainty about the multi-parameter estimation can thus be formulated in terms of the corresponding particles' volume[37]. For each explored  $\hat{H}_j(\mathbf{x}_j)$ , QHL is performed by updating a distribution along  $N_{\mathrm{E}}$  epochs, each corresponding to a single experiment performed on the system. The experiment design here is left to a heuristic rule within QHL, which can easily be replaced by more sophisticated methods when required[34]. Each experiment involves (1) preparing the electron spin in the chosen probe state  $|\psi\rangle$ , (2) evolving the spin for a chosen evolution time  $t$  (according to a heuristic rule; Supplementary section 1C2) and performing a final projective measurement on a chosen basis, here  $|d\rangle \in \{|0\rangle, |1\rangle\}$ . The measurement yields a binary datum  $d \in \{0,1\}$ . The choice of  $|\psi\rangle$  is random, whereas  $t$  follows a heuristic rule. In practice, data for a given  $t$  in Figs. 2f and 3e are obtained by repeating the experiment 10^6 times, and  $d$  is extracted via majority voting. The Bayes update for any particle  $\mathbf{x}_i$  is obtained by invoking a trusted simulator, to compute the likelihood  $\mathcal{L}(d|\hat{H}_j,\mathbf{x}_j,|\psi\rangle,t) = \langle d|\mathrm{tr}_{\mathrm{env}}[\rho_\Psi(t)]|d\rangle_{\mathrm{sys}}$ , where  $\rho_\Psi$  is the global density matrix corresponding to the evolved state  $\mathrm{e}^{-\mathrm{i}tH_j(\mathbf{x})t}|\psi\rangle_{\mathrm{sys}} \otimes |\phi\rangle_{\mathrm{env}}$ . The obtained likelihood is then adopted to apply Bayes' rule. In this way, the belief about the optimal parameterization is updated until a final estimate  $\mathbf{x}_j'$ , retrieved after updating the prior  $P(\mathbf{x}_j)$  against the experimental evidence provided by the cumulative dataset  $D_j = \{d\}$ . A complete description of how QHL was generalized to run in this experiment is provided in Supplementary section 1C.

The two fundamental phases of QMLA are the consolidation and growth of the DG. During the consolidation of a layer  $\mu$ , all  $\hat{H}_i^{\prime} \in \mu$  are compared pairwise according to their BF, defined in equation (1). Directed edges between  $(\hat{H}_i, \hat{H}_j)$  represent  $\mathcal{B}_{ij}$  in the cDG, with directionality indicating performance; that is,  $\mathcal{B}_{ij} \gg 1$  ( $\mathcal{B}_{i,j} \ll 1$ ) indicates that  $\hat{H}_i(\hat{H}_j)$  is superior (Fig. 1c). In a given consolidation among any subset of models  $\{\hat{H}_k\}$ , the champion(s) is the node(s) that is highest in degree, that is, winning the most pairwise comparisons. In particular, in a given layer  $\mu$  we use consolidation to rank models or to determine a single layer champion  $\hat{H}_{C(\mu)}$ . Growing the DG corresponds to an exploration stage, whereby a new layer  $\nu$  is generated, consisting of new models that inherit properties from the latest layer champion  $\hat{H}_{C(\mu)}$  or a subset of top-ranked models among those already trained. The way new candidates are generated is regulated by the ESs, which allow a degree of flexibility in QMLA to adapt to different scenarios, according to the amount of a priori information available to the user. QMLA is designed to represent models as a combination of independent terms that map directly to physical interactions, rendering the output of the procedure easily interpretable and, if the system of concern is tunable, actionable. Termination criteria can involve observing  $\mathcal{B}_{C(\nu), C(\mu)} \ll 1$ , that is, a significant decrease in performance between parent layer  $\mu$  and child layer  $\nu$ , or simply reaching a fixed maximum depth of the sDG. We discuss, in the following, the ESs used for this Article.

Experimental set-up details. QMLA tests were run against experimental data obtained from a NV centre with optical initialization and readout via a confocal set-up and electron spin state addressing via microwave fields. The basis set for measurements was chosen as the ground states with  $m_{\mathrm{s}} = \{0, -1\}$ , customarily adopted as the computational basis for this system. The choice is reflected, experimentally, in the final  $\pi / 2$  microwave pulse applied to the electron spin to prepare the (optical) projective measurement. The data points reported in Figs. 2e and 3f were obtained by repeating each sequence three million times. The contribution from Poissonian noise in the measurement is thus rendered too small to appear as error bars in said figures, whereas other sources of noise in the set-up are uncharacterized. A thorough model to reproduce the dynamics of this system is provided via<sup>38</sup>

$$
\begin{array}{l} \hat {H} _ {\text {f u l l}} = \Delta_ {\mathrm {g s}} \hat {S} _ {z} ^ {2} + \mu_ {\mathrm {B}} \mathbf {g} \cdot \mathbf {B} \cdot \hat {S} + \hat {S} \cdot \sum_ {\chi} \left(\mathbf {A} _ {\chi} \cdot \hat {I} _ {\chi}\right) (3a) \\ + P \hat {I} _ {z} ^ {2} + \mu_ {\mathrm {n}} \mathbf {g} _ {\mathrm {n}} \cdot \mathbf {B} \cdot \sum_ {\chi} \hat {I} _ {\chi}, (3b) \\ \end{array}
$$

where  $\hat{S}$  and  $\hat{I}$  are the total electron and nuclear spin operators respectively,  $\mathbf{B}$  is the magnetic field,  $\mu_{\mathrm{B(n)}}$  is the Bohr (nuclear) magneton,  $\mathbf{A}$  and  $\mathbf{g}_{\mathrm{(n)}}$  are the hyperfine and electron gyromagnetic tensors, and  $\Delta_{\mathrm{gs}}$  and  $P$  the zero-field and quadrupole splittings. The first two terms and equation (3b) capture the intrinsic dynamics of the electron and of each nuclear site  $\chi$  included in the model, whereas the last term in equation (3a) describes the hyperfine coupling between the nuclear bath and the electron spin, that is, open system dynamics. Several approximations can be applied to  $\hat{H}_{\mathrm{full}}$ , according to the expected characteristics of the bath and the experiment performed. For the scope of studying the fast dynamics (Fig. 2), where we focus on retrieving the interaction of the electron spin with its environment, we

have always neglected the contributions from the zero-field splitting  $(\varDelta_{\mathrm{gs}}\hat{S}_z^2)$  as well as the quadrupole interaction  $(P I_z^2)$ . This is because these two terms produce constant shifts on the fine states and a splitting on the nitrogen hyperfine states, respectively, which hardly contribute at all to the short decay. For the analysis summarized in Fig. 2, the hyperfine interaction term  $\hat{S}\cdot \sum_{\chi}\mathbf{A}_{\chi}\cdot \hat{I}_{\chi}$  in equation (3b) is replaced by the compact representation  $\hat{A}_{xyz}$ . This change amounts to mapping all nuclear contributions to a single environmental qubit: this is legitimate either in the case when the interaction with a single nuclear site is dominant compared to other contributions or also when the analysis does not involve the revivals that are expected at times dictated by echo effects, evidently characterizing the experiment in Fig. 3e. In the main text we refer to the set of credible models, that is, those compatible with the full model of equation (3b), when simplified with various approximations. Excluding the splitting terms, assuming a static bath and labelling with  $z$  the symmetry axis of the NV centre, the list is as follows:  $\{\{\hat{S}_z\hat{A}_z\},\{\hat{S}_z\hat{A}_zT_{xz},\hat{S}_z\hat{A}_zT_{yz}\},\{\hat{S}_z\hat{A}_zT_{xz,yz}\},\{\hat{S}_{xz}\hat{A}_{xz},\hat{S}_{yz}\hat{A}_{yz}\}$ ,  $\{\hat{S}_{xyz}\hat{A}_{xyz},\hat{S}_{xyz}\hat{A}_{yz}\}$ ,  $\{\hat{S}_{xyz}\hat{A}_{xz},\hat{S}_{xyz}\hat{A}_{yz},\hat{S}_{xyz}\hat{A}_{z}\}$ ,  $\{\hat{S}_{xyz}\hat{A}_{xyz}T_{xz},\hat{S}_{xyz}\hat{A}_{xyz}T_{yz}\}$ ,  $\{\hat{S}_{xyz}\hat{A}_{xyz}T_{xz},\hat{S}_{xyz}\hat{A}_{xyz}T_{yz}\}$ . The groupings correspond to the (apparent) progressive level of detail captured by the various models. These models are but a small subset of the  $2^{9}$  models that can potentially be generated by QMLA when exploring the cases summarized in Fig. 2, and only five of them are consistently retrieved by QMLA. Further details about this choice for a credible set and their occurrence in QMLA runs are provided in Supplementary Section 3A. Finally, we observe how the breakdown of hyperfine effects in diagonal and transverse contributions (adopted in the main text) typically leads to a specific nomenclature for the parameters appearing in  $\sum_{j\in \{x,y,z\}}\alpha_j$  ( $\hat{\sigma}_j\otimes \hat{\sigma}_j$ ):  $\alpha_{z}$  is the axial element ( $A_{\parallel}$ ), whereas  $\alpha_{x},\alpha_{y}$  —expected to be equal—are the non-axial elements ( $A_{\perp}$ ) of the hyperfine tensor.

The greedy search exploration strategy. We provide here a synthetic discussion of the ESs used in this Article. Further details are provided in Supplementary Section 1D. In the first test of QMLA (all analyses referring to Fig. 2), we employ a greedy exploration strategy' to implement the inheritance principle (see main text). For each layer, terms are added individually from a predefined set of primitives, with subsequent layer champions  $\hat{H}_{C(\mu)}$  informing QMLA about which terms to remove next. When the set of available terms is empty, QMLA either increases the dimension characterizing candidate models or terminates. With this ES, given that the assignment of every possible candidate model to a layer is univocal, all graphs employed for the search are acyclic. Formally, this ES proceeds as follows:

(1) Single-qubit rotation terms are adopted as primitives:  $\mathbb{S} = \{\hat{S}_x,\hat{S}_y,\hat{S}_z\}$ , and are placed as nodes on the first layer.  
(2) New layers construct new models by adding a single term from  $\mathbb{S}$ , building on the latest  $\hat{H}_{\mathrm{C}(\mu)}$ , until all available terms in  $\mathbb{S}$  are exhausted.  
(3) Hilbert space dimension is increased by introducing hyperfine terms  $\{\hat{A}_x,\hat{A}_y,\hat{A}_z\}$ , added individually by layer as in (2).  
(4) Transverse terms  $\{\hat{T}_{xy},\hat{T}_{xz},\hat{T}_{yz}\}$  are introduced and added as in (2).

In this way, QMLA is effectively limited to nine-parameter spin models up to two qubits. The set of primitives is rather generic, but we limit the possible combinations and organize them in batches, informing QMLA with a priori hypotheses about the system. Finally, the termination rule here was that QMLA should exhaust the entire pool of terms permitted by the ES. We deactivate any alternative flags described in the main text that permit early termination, to gather statistics for BFs also involving overfitting models.

The genetic algorithm exploration strategy. As opposed to the strict schedule of the greedy search outlined above, we also test an ES mediated through a GA. With this strategy, the inheritance principle is generalized to include more than one parent for each new generation of models, chosen with a probability proportional to an appropriate fitness function (see equation (4)). In particular, at any given moment there are  $N_{\mathrm{m}} = 72$  models active in the DG, and the strongest  $N_{\mathrm{m}} / 6$  among them provide a pool of potential parents, which spawn a further  $N_{\mathrm{m}}$  models to place on a new layer of the sDG. The procedure is iterated for up to  $N_{\mathrm{g}} = 60$  generations (layers of the sDG), although the termination criterion stipulates that the search cease if one model remains the strongest for several consecutive generations. As mentioned in the main text, this ES also belongs to the general framework reported in Fig. 1, where (1) the initial layer of chromosomes in the sDG is randomly sampled from the population of valid models, (2) the rating of models within a layer leads to assigning each a selection probability, (3) new candidates are generated via the GA, by selecting and crossing-over two parents from the previous generation and (4) the layer corresponding to the parent generation is immediately deactivated from the cDG. For the analysis in the main text, we assume access to an underlying parameter-learning subroutine, because the exponential overhead of CLE deems it is impractical to perform parameter learning for  $N_{\mathrm{m}} \times N_{\mathrm{g}} \approx 4,000$  models with several qubits on classical simulators (although, in practice, GA repeats models and terminates early most often, so most QMLA instances construct only ~1,000 models in total). Our focus, instead, is on the validity of the GA approach by allowing access to the exact parameterization of each proposed model  $\mathbf{x}_j^0$ . GAs rely on an objective function to differentiate between models' strengths, and we must design such a quantity based on the outcomes of a set of experiments,  $E = \{e\}$ , each consisting of an evolution time  $t$  and an input

state  $|\psi \rangle$ . A possible choice would be to use the cumulative log-likelihood, already introduced with equation (1) in the main text, against the binary dataset  $\{D|E\}$ . However, we observe how the experimental datasets used in this work, such as those available from other quantum devices, provide access directly to an estimate of the likelihood  $\mathcal{L}(d|\hat{H}_0,\mathbf{x}_0,|\psi \rangle ,t)$ , instead of binary outcomes. Within the realm of parameter estimation, the opportunity to use single-shot measurements instead of cumulative statistics for the same  $E$  has been discussed at length[17,57]. Here, we are simply concerned with optimizing computational overheads, as a simulated system also provides natural access to a likelihood estimate, from which single-shot data would be sampled. Therefore, it is here a sensible choice to quantify how well candidate model  $\hat{H}_j$  performs when compared with the true system, with respect to  $E$ , by

$$
g _ {j} = \left(1 - \frac {1}{| E |} \sum_ {e \in E} r _ {j | e}\right) ^ {2}, \tag {4}
$$

where the residuals  $r_{j|e} = \left|\mathcal{L}(0|\hat{H}_0,\mathbf{x}_0,e) - \mathcal{L}(0|\hat{H}_j,\mathbf{x}_j^0,e)\right|$ . Adopting equation (4) as the objective function in our GA has an intuitive justification: models that can faithfully reproduce the dynamics generated by  $\hat{H}_0$  are more likely to share the same Hamiltonian terms, and are therefore favoured for parenthood. The strongest models therefore exhibit  $g\approx 1$ , whereas the weakest have  $g\approx 0$ . We can thus use  $g_j$  to dictate the GA as the probability of selecting  $\hat{H}_j$  as a parent for models in the newly generated layer; that is, we perform a roulette selection to select parents<sup>58</sup>.

QMLA with hyperparameterized likelihoods. Furthermore, the dynamics of the NV centre observed in long decays via Hahn-signal experiments (Fig. 3e) can be interpreted in terms of the hyperfine interaction among the electron spin and neighbouring nuclei described by equation (3b). Hahn-echo experiments are designed to minimize the contribution of the bath to the system dynamics, so collective phenomena are expected to dominate individual spin contributions<sup>59</sup>. It was observed that the unitary evolution originated from  $\hat{H}_{\mathrm{full}}$  can be solved analytically under a few assumptions<sup>40</sup>, leading to the formula

$$
\mathcal {L} (1 | t; \left\{\mathbf {B} ^ {j} \right\}, \left\{\omega_ {j} \right\}) = \left(\prod_ {j} \left(S _ {j}\right) + 1\right) / 2, \tag {5}
$$

for the likelihood, in terms of pseudospins

$$
S _ {j} = 1 - \frac {\left| \mathbf {B} _ {0} \times \mathbf {B} _ {1} ^ {j} \right| ^ {2}}{\left| \mathbf {B} _ {0} \right| ^ {2} \left| \mathbf {B} _ {1} ^ {j} \right| ^ {2}} \sin^ {2} \left(\omega_ {0} t / 2\right) \sin^ {2} \left(\omega_ {j, 1} t / 2\right), \tag {6}
$$

with  $\mathbf{B}_0$  being the external magnetic field and  $\omega_0$  the bare Larmor frequency. The remaining parameters can be interpreted by thinking of the NV electron spin, in state  $m_{s}$ , coupled to the  $\chi$ th nuclear spin, as a four-level system  $\mathcal{E}$ . The evolution of  $\mathcal{E}$  can be described in terms of effective magnetic field  $\mathbf{B}_{m_s}^{\prime}$  (which takes into account the different  $\mathbf{B}_0$  at different nuclear sites), whereby the ground states of  $\mathcal{E}$  precess at a rate  $\omega_{j,0}$ , whereas the excited states incur a splitting  $\omega_{j,1}$  (refs.

40,41,60). Adopting this description, after the initial  $\pi /2$  pulse, in free evolution the nuclear and electron spin become progressively more entangled at a rate dictated by the hyperfine interaction, becoming maximally correlated at times  $t\propto \pi /A$  , where the Hahn signal is weakest. When the two spins get disentangled again, revivals can be observed in the experimental Hahn-echo signal (Fig. 3). Observing equation (6), decays and revivals in the photoluminescence signal can then be interpreted, respectively, as beatings among the modulated frequencies  $\omega_{j,1}$  , and re-synchronization when  $t = 2\pi /\omega_0$  . See Supplementary section 3A for further details.

The analytical likelihood in equation (5) involves a degenerate parameterization; that is, any permutation of several elements of an optimal  $\mathbf{x}^{\prime}\equiv \{\mathbf{B}^{j},\omega_{j}\}$  is also an optimal solution. In such conditions, the learning via QHL methods is performed most efficiently via a hyperparameterization, because degeneracies in  $\mathcal{L}$  are known to mislead sequential Monte-Carlo algorithms (which implicitly assumes unimodal priors), a problem addressed recently in ref. by adopting clustering methods. We construct a hyperparameterization of the problem, using two normal distributions  $\mathcal{N}(B_1,\sigma_B)$  and  $\mathcal{N}(\omega_0 + \delta_\omega ,\sigma_\omega)$ , from which a number  $n_j^s$  of  $\mathbf{B}_1^s$  and  $\omega_{j,1}$  are drawn. In this way, for each tentative  $n_j^s$ , a CLE instance can be performed against a reduced hyperparameter set,  $\mathbf{x}\coloneqq \{\mathbf{B}_0,\mathbf{B}_1,\sigma_B,\omega_0,\delta_\omega ,\sigma_\omega \}$ . Hyperparameters, however, effectively reduce the complexity of the trained model. For example, here, a parameterization of cardinality  $4n_j^s$  (referring to equation (6)) is transformed into a hyperparameterized learning of six parameters  $\forall n_j^s$ . Hence, BFs cannot detect overfitting, and termination conditions based on BFs would not work. To estimate a credible number of interacting spins,  $n_j^s$ , producing the observed dynamics, we use an MHA that approximates the distribution of  $P(n^{s})$ . In particular, for each MHA iteration, a new tentative  $n_{j + 1}^{s}$  is sampled and  $N_{e}$  epochs of CLE are performed. The probability of accepting  $n_{j + 1}^{s}$  as representative of the distribution is taken as  $\mathcal{B}_{j + 1,j}(D)$ , with  $D$  being the cumulative set of experimental data collected throughout all MHA iterations so far. In this way, higher values of  $n_j^s$  are kept only if they are statistically justified by a better reproduction of the data.

Details about QMLA simulations. In the main text, we have discussed the outcome of simulating QMLA in different scenarios. Here we report additional details concerning said simulations. The analyses reported in Fig. 2 for the cases labelled as 1 to 3 in the main text were all run for 500 independent QMLA instances to gather sufficient statistics highlighting the algorithm performances. In more detail, case 1 is intended to be the least biased scenario, as the results mediate across a variety of true models tested  $(\hat{H}_0 \in \{\hat{S}_{xyz}, \hat{S}_{xyz}\hat{A}_z, \hat{S}_{xyz}\hat{A}_{xy}, \hat{S}_{xyz}\hat{A}_{xyz}, \hat{S}_{xyz}\hat{A}_{xyz}\hat{T}_{xz}\}$ , picked randomly for each QMLA instance) and we assume complete control over the initial global state (that is, QMLA is deemed capable of preparing an arbitrary separable probe state  $|\psi\rangle = |\psi\rangle_{sys} \otimes |\phi\rangle_{env}$ ). In reality, for our test-bed NV system, the electron spin is always prepared in the superposition state  $|+\rangle$ , and the nuclear bath is (at least approximately) unpolarized at the start of the Hahn sequence. In hyperpolarization experiments it is customary to assume, at site  $j$ ,  $|\phi\rangle_{env,j} = p_j|\uparrow\rangle + (1 - p_j)|\downarrow\rangle$ , with  $p_j \in [0,1]$  (ref. 62). In cases 2 and 3 we choose probe states compatible with this assumption, adopting  $p_j \approx 0.5$  to take into account the negligible polarization exhibited by the nuclear bath (mapped onto a single environmental qubit state), but introducing a phase  $\varphi$  in  $|++'\rangle$ .  $\varphi$  would usually be omitted in hyperpolarization modelling, as  $\varphi$  is not detected by those experiments. In case 2, we adopt the outcome of case 3, that is,  $\hat{H}_0 = \hat{S}_{xyz}\hat{A}_z$ , to perform the same modelling task, but without the noise introduced by the experiment. Finally, the simulations for the GA in Fig. 3 adopt 100 QMLA independent instances,  $N_m = 72$  models per generation, and each instance is halted after a maximum of  $N_g = 60$  generations, although it can terminate earlier if converged. The GA adopts a one-point crossover and a  $25\%$  mutation rate. As for case 1 above, to reduce biases, validation experiments  $|E_\nu| = 100$  use probe states that span the tomographic basis, and  $t \in (0,100\mu s)$  for a realistic timescale as in Fig. 3e, with  $|E_\nu| = 100$ . As mentioned in the main text, pairwise comparisons among models need to reflect their fitness at reproducing  $\hat{H}_0$ .

# Data availability

Data and analysis scripts are available at https://figshare.com/s/  
caf2581da7eb2414fc7f. The data are presented in CSV format with analysis in Python using Pandas and NumPy libraries.

# Code availability

Our code, written in Python and implemented via the Portable Batch System for parallel processing, is available at https://github.com/flynnbr11/QMLA, with documentation at https://quantum-model-learning-agent.readthedocs.io/en/latest/.

# References

56. Gali, A. Identification of individual  $^{13}\mathrm{C}$  isotopes of nitrogen-vacancy center in diamond by combining the polarization studies of nuclear spins and first-principles calculations. Phys. Rev. B 80, 241204 (2009).  
57. Dinani, H. T., Berry, D. W., Gonzalez, R., Maze, J. R. & Bonato, C. Bayesian estimation for quantum sensing in the absence of single-shot detection. Phys. Rev. B 99, 125413 (2019).  
58. Goldberg, D. E. Genetic Algorithms in Search, Optimization and Machine Learning (Addison-Wesley, 1989).  
59. Balian, S. J., Wolfowicz, G., Morton, J. J. L. & Monteiro, T. S. Quantum-bath-driven decoherence of mixed spin systems. Phys. Rev. B 89, 045403 (2014).  
60. Breuer, H.-P. & Petruccione, F. The Theory of Open Quantum Systems (Oxford Univ. Press, 2007).  
61. Liu, J. & West, M. Combined Parameter and State Estimation in Simulation-Based Filtering (Springer, 2001).  
62. Broadway, D. A. et al. Quantum probe hyperpolarization of molecular nuclear spins. Nat. Commun. 9, 1246 (2018).

# Acknowledgements

We thank C. Bonato, F. Jelezko, F. Marquardt, T. Fösel, C. Woods, J. Wang, M. G. Thompson, A. Paiement, A. Cimarelli, P. Yard and J. Bulmer for useful discussions and feedback. A.A.G., S.K., S.P. and R.S. acknowledge support from the Engineering and Physical Sciences Research Council (EPSRC), programme grant no. EP/L024020/1. B.F. acknowledges support from Airbus and EPSRC grant EP/P510427/1. N.W. was funded by a grant from Google Quantum AI, the NQI center for Quantum Co-Design, the Pacific Northwest National Laboratory LDRD programme and the 'Embedding Quantum Computing into Many-Body Frameworks for Strongly Correlated Molecular and Materials Systems' project, funded by the US Department of Energy (DOE). J.G.R. acknowledges support from EPSRC (EP/M024458/1). A.L. acknowledges fellowship support from EPSRC (EP/N003470/1). This work is supported by the UK Hub in Quantum Computing and Simulation, part of the UK National Quantum Technologies Programme with funding from UKRI EPSRC grant no. EP/T001062/1, and by the European project QuCHIP (Quantum Simulation on a Photonic Chip; grant agreement no. 641039). This work was carried out using the computational facilities of the Advanced Computing Research Centre, University of Bristol (http://www.bristol.ac.uk/acrc/).

# Author contributions

R.S., A.A.G. and N.W. conceived the methodology. B.F., A.A.G. and R.S. performed simulations with support from N.W., S.P. and C.E.G. S.K. built the set-up and performed the experiments under the guidance of J.G.R. A.A.G., R.S., B.F. and S.P. analysed and interpreted the data with support from N.W., S.K. and C.E.G. A.A.G., R.S., B.F., S.K., N.W., S.P., C.E.G. and A.L. wrote the manuscript. R.S. and A.L. supervised the project.

# Competing interests

The authors declare no competing interests.

# Additional information

Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41567-021-01201-7.

Correspondence and requests for materials should be addressed to R.S.

Peer review information Nature Physics thanks Dong-Ling Deng and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.

Reprints and permissions information is available at www.nature.com/reprints.