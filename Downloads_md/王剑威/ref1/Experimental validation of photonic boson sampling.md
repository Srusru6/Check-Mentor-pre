# Experimental validation of photonic boson sampling

Nicolò Spagnolo<sup>1</sup>, Chiara Vitelli<sup>1,2</sup>, Marco Bentivegna<sup>1</sup>, Daniel J. Brod<sup>3</sup>, Andrea Crespi<sup>4,5</sup>, Fulvio Flamini<sup>1</sup>, Sandro Giacomini<sup>1</sup>, Giorgio Milani<sup>1</sup>, Roberta Ramponi<sup>4,5</sup>, Paolo Mataloni<sup>1</sup>, Roberto Osellame<sup>4,5*</sup>, Ernesto F. Galvão<sup>3*</sup> and Fabio Sciarrino<sup>1*</sup>

A boson sampling device is a specialized quantum computer that solves a problem that is strongly believed to be computationally hard for classical computers. Recently, a number of small-scale implementations have been reported[2-5], all based on multiphoton interference in multimode interferometers. Akin to several quantum simulation and computation tasks, an open problem in the hard-to-simulate regime is to what extent the correctness of the boson sampling outcomes can be certified[6,7]. Here, we report new boson sampling experiments on larger photonic chips and analyse the data using a recently proposed scalable statistical test[8]. We show that the test successfully validates small experimental data samples against the hypothesis that they are uniformly distributed. In addition, we show how to discriminate data arising from either indistinguishable or distinguishable photons. Our results pave the way towards larger boson sampling experiments whose functioning, despite being non-trivial to simulate, can be certified against alternative hypotheses.

Large-scale quantum computers hold the promise of efficiently solving problems that are believed to be intractable for classical computers, such as integer factoring. We are, however, far from being able to experimentally demonstrate a large-scale, universal quantum computer<sup>10</sup>. This has motivated the recent study of different classes of restricted quantum computers<sup>11,12</sup>, which may provide a more feasible way of experimentally establishing what has been called quantum computational supremacy<sup>13</sup> over classical computers.

One example of such restricted quantum computers comprises multimode interferometers designed to solve the boson sampling problem $^{1}$ , as recently demonstrated in small-scale photonic experiments $^{2-5}$ . The boson sampling problem consists of simulating the following quantum experiment (Fig. 1a,b): input  $n$  bosons in different modes of an  $m$ -mode linear interferometer ( $m > n$ ) and measure the distribution of bosons at the interferometer's output modes. If performed with indistinguishable bosons, this experiment results in an output distribution that is hard to sample, even approximately, on classical computers $^{1}$  (under very mild computational complexity assumptions). In fact, the calculation of the probability associated with each observed boson sampler (BS) event requires the estimation of a permanent, a notoriously intractable matrix function $^{1}$ . The input for the classical simulation consists of the  $m \times m$  unitary matrix  $U$  describing the interferometer and the list of  $n$  input modes used. It is desirable to choose  $U$  randomly, both to avoid regularities that could simplify

the classical simulation and because the main hardness-of-simulation argument of ref. 1 holds only for uniformly sampled unitaries. These recent theoretical and experimental results motivated further investigations on error tolerances $^{14,15}$ , as well as additional analyses of optical implementations $^{16,17}$ . Other approaches have been proposed to implement boson sampling, among them the use of trapped ions $^{18}$ .

The significant development of quantum technologies in the last few years has led to the implementation of platforms where nontrivial quantum tasks can be addressed, ranging from quantum simulation to quantum computing. An open problem is to what extent the correctness of the outcomes can be certified. In this framework, boson sampling represents a relevant benchmark for testing different procedures to validate the obtained calculation/ simulation. Indeed, the number of possible experimental outputs is given by the binomial coefficient  $\binom{m}{n}$ , which increases exponentially with  $n$  (in the hypothesis that  $m \gg n$ ). Consequently, it seems hard to validate the obtained outcome distributions with an experimental data set of polynomial size (in  $n$ ). Recently, a first insight into this issue was obtained by Gogolin and colleagues, who showed that so-called symmetric algorithms fail to distinguish the distribution of experimental data even from the trivial, uniform one. This analysis positively stimulated research on the complexity of linear optics and put in question the notion that larger boson sampling experiments could be shown to decisively outperform classical computers.

Recently, the argument developed in ref. 7 has been refuted by Aaronson and Arkhipov<sup>8</sup>, who argued that it was unreasonable to restrict the statistical analysis to symmetric algorithms only. Moreover, Aaronson and Arkhipov proposed to discriminate data against the uniform distribution by taking advantage of the input information of the boson sampling problem (unitary  $U$  and the list of input modes). They proposed a scalable validation test that, for large enough  $n$  and uniformly drawn unitaries, succeeds with high probability using only a constant number of samples.

Here, we report photonic boson sampling experiments performed with three photons in randomly designed integrated chips with 5, 7, 9 and 13 modes, corresponding to 10, 35, 84 and 286 different no-collision outputs, that is, outputs with at most one photon per mode. We analyse the experimental data using the Aaronson-Arkhipov validation test<sup>8</sup>, showing that the test works in practice, even in the presence of experimental imperfections. We also show how we can successfully discriminate

![](images/e6595214d73165839e45a8b8234d62ef8c1f7d3eb9705bc1285fa3e89d399b6d.jpg)

![](images/a339ba977114257904f9e8cd22e1370b014d5c64a3a8ca52cdd2ef4d39b1cd4b.jpg)

![](images/58c0b3b540bdb72236c91060d6d3fb8e8678df2e03b1a8d796d8a258acbfba9d.jpg)  
Figure 1 | Boson sampling and its certification. a, The boson sampling problem consists of sampling from the output distribution of  $n$  bosons evolving according to a linear transformation  $U$ . The  $m \times m$  unitary matrix  $U$  together with the input state are known quantities in the problem. b, Photonic implementation of boson sampling:  $n$  indistinguishable photons interfere in a random, linear  $m$ -mode interferometer, with photodetection at the output modes. Let us call the boson sampler (BS) an agent that provides events generated by a boson sampling experiment; our implementation is shown schematically. c, The uniform sampler (US) is an agent that generates events classically according to a uniform distribution over outputs. d, A third agent, the certifier Caesar, exploits information about  $U$  to distinguish the output data sets generated by the boson sampler from those generated by the uniform sampler.

![](images/86f64f8648b3cffaf1d72f37c45b042184a4c1b3b94a8c942f5479b934396b10.jpg)

![](images/cda2d373d471116454274b38b13e92a8fc745ced82ff9255d24dbc79136257cb.jpg)

![](images/41150f94e494302b63b89af9f7cba1830395a5d493e81db2ff234cdfa9aeb348.jpg)

![](images/1620b971ea5c300761a06d333dd87b38d03d058dac76d7a7804c0fa7b5cc5c01.jpg)

![](images/336478bbfbb50ea8223ae7b72ba7e84f9965c8e605a0001eee4d714a880f0160.jpg)  
Figure 2 | Experimental validation of boson sampling. a-d, Performance of the validation test proposed in ref. 8 using experimental data sets of varying sizes. Here, we show Caesar's success rate  $P_{\text{success}}$  in distinguishing the sets, as a function of set size  $N_{\text{set}}$ , in experiments using one random Haar-uniform 5-mode interferometer (a), one random 7-mode interferometer sampled with four different three-photon input combinations (b), one random 9-mode interferometer sampled with two different three-photon input combinations (c), and one random 13-mode interferometer (d). Error bars are due to the number of collected events. Grey dashed line: level for  $95\%$  success probability. Square points: numerical simulations, averaged over 1,000 data sets of size  $N_{\text{set}}$ , of the validation test for data generated by the uniform sampler. In all plots, blue shaded regions correspond to the theoretical prediction of the boson sampling validation, reported as 1.5 standard deviations and obtained by averaging over a numerical simulation with 1,000 Haar-uniform unitaries. Green shaded regions correspond to the theoretical prediction for the validation of a uniform sampler, reported as 1.5 standard deviations over a numerical simulation with 1,000 Haar-uniform unitaries. e, Minimum data set size  $N_{\text{min}}$  to obtain  $>95\%$  success probability for boson sampling experiments and to obtain  $<5\%$  success probability for uniformly sampled experiments, as a function of the number of photons  $n$  and of the number of modes  $m$  obtained through a numerical simulation. For each point, the simulation is averaged over 50 or 100 Haar-uniform unitaries.

![](images/72187214a612281cc0b27d311cf062bf56d75862ea80fbc1752062c1295a01e1.jpg)

![](images/86d620cbad3ff42e68d888b93a358b7037ea0a27fdbaff42bb0e6e531d455668.jpg)

![](images/80674f8bf5a1f3fbf67e7feecbe482293f9e9aa6d29a093598896af2b4286542.jpg)

![](images/5a5dae40940fc4bdf94341f514c68d46243e55d4053e4beb9118fe60cffe7960.jpg)

![](images/4198e513750eea6c5a8d0b14239c3f6513509e86e342c70a08e5b0ecbf16d329.jpg)  
Figure 3 | Full validation of the boson sampling experiments. Here, we compare the experimentally measured probabilities  $P_{\mathrm{out}}$  of all no-collision outputs of our boson sampling experiments (blue bars), based on the full set of experiments we performed, with the expected probabilities (yellow bars) for a random 7-mode chip with input modes (3, 4, 5) (a), a random 9-mode chip with input modes (4, 5, 6) (b), a random 13-mode chip with input modes (6, 7, 8) (c). The expected probabilities take into account the partial photon distinguishability of the source and multiphoton events (see Methods and refs 2 and 26). Lighter regions of the blue bars correspond to experimental error, which is due to the Poissonian statistics of the events. d-g, Application of the Aaronson-Arkhipov test to the full set of experimental data. C is a counting variable that is increased by 1 for each event assigned to the boson sampler, and decreased by 1 for each event assigned to the uniform sampler. When  $C > 0$ , the complete data set is assigned to the boson sampler. Blue points: test applied on the experimental data. Green points: test applied on simulated data generated by the uniform sampler.

![](images/0ed3eedba0371e61af6c66f75b6526cc44cf76a82c19d3c25c25d839ddf059b4.jpg)

![](images/b277f7c798716f8228d7508e42be5e653350971e8a9b1285909b93685f17fb9a.jpg)

![](images/56d1a67565dcfcb2245099a6b26dc9e022cdb0526382377e12ade9cdf4b87e68.jpg)

data corresponding to distinguishable and indistinguishable photons in these experiments.

To perform boson sampling experiments we used three ingredients: a three-photon source, randomly designed interferometers and a detection apparatus able to record all the three-photon coincidence events at the output of the interferometer (Fig. 1b). The three-photon input state is produced by exploiting the second-order parametric downconversion process, with three photons sent into the interferometers and a fourth used as a trigger. We fabricated stable, integrated interferometers with 5, 7, 9 and 13 modes in a glass chip by femtosecond laser waveguide writing[19-21]. This technique consists of a direct inscription of waveguides into the glass volume, exploiting the nonlinear absorption of focused femtosecond laser pulses to induce a permanent and localized increase in the refractive index. Single photons may jump between waveguides by evanescent coupling in regions where waveguides are brought close together, thus realizing the beamsplitter transformation. Precise control of the coupling between the waveguides and of the photon path lengths, enabled by a three-dimensional design[2], allowed us to engineer arbitrary interferometers by cascading directional couplers and phase shifters with different layouts (Fig. 1b and refs 2, 22-26). Finally, single-photon counting detectors and an

electronic acquisition apparatus were used to reconstruct the probabilities associated with all three-photon coincidence events at the chip's output. Further details on the integrated circuits and the experimental set-up are provided in the Methods and in Supplementary Fig. 1 and Supplementary Section 'Experimental apparatus, generated state and six-photon contributions'.

Let us now discuss how a certifier (Caesar) can validate, already with small sets, boson sampling data generated by an agent we call the BS, against the hypothesis that they might have been generated by uniform sampler (US), an agent that samples from the uniform probability distribution (Fig. 1b-d). Caesar succeeds by applying the Aaronson-Arkhipov statistical test to a small sample of output data. Caesar calculates an estimator  $P$ , correlated with the associated BS probability, which, differently from the permanent, is efficiently computable.  $P$  is expected to be higher, on average, for observed events, which signals a departure from the uniform distribution (see Methods for details). We have applied this test to multiple, random experimental data sets of varying sizes so as to gauge the trade-off between set size and success rate, which has been theoretically studied only for large enough  $n$ . The results are shown in Fig. 2. For the experiments with the 5-, 7-, 9- and 13-mode chips, Caesar reaches a  $95\%$  average success rate using very modest set size.

![](images/c348c15aa7aa5232b3d828f5c23dde2fa625a7171b17942456da2eefdd2ccace.jpg)  
a  
7-mode interferometer Input modes: (3,4,5)

![](images/cd55bc03b5329f9501c715cf6cf14b227e42058666b9333f22805d198bc29c38.jpg)  
b  
9-mode interferometer Input modes: (4,5,6)

![](images/518133883f3be03c012b5871e17c42268a483c2fdf2995a24c04710aeec469ec.jpg)  
c  
13-mode interferometer Input modes: (6,7,8)

![](images/b62e4d6fac16b3427fa4289cf7ba118ae285309e01c2af2d9727832816d2442f.jpg)  
Figure 4 | Discrimination between alternative distributions. Experimental results of the discrimination between boson sampling and distinguishable sampling for the 7-mode chip with input modes (3, 4, 5) (a), the 9-mode chip with input modes (4, 5, 6) (b) and the 13-mode chip with input modes (6, 7, 8) (c). Evaluation of discriminator  $D$  of the likelihood ratio test (see Methods for definition) for data collected with indistinguishable photons (blue points) and distinguishable photons (red points). More experimental data are reported in Supplementary Figs 3-6. d, Numerical simulation of the minimum set size  $N_{\mathrm{min}}$  to obtain  $>95\%$  success probability for boson sampling experiments and to obtain  $<5\%$  success probability for distinguishable sampling experiments, as a function of number of photons  $n$  and number of modes  $m$ . For each point, the simulation is averaged over 100 Haar-uniform unitaries.  
d

sizes of just  $\sim 100$  events. This establishes experimentally the usefulness of the Aaronson-Arkhipov test for the analysis of small-scale experiments.

To show the test will also work in as yet unperformed, larger-scale experiments, in Fig. 2e we numerically determine the minimum data set size  $N_{\mathrm{min}}$  for which the Aaronson-Arkhipov test discriminates boson sampling data from the uniform distribution (and vice versa) with a success rate of  $>95\%$ . Not only is  $N_{\mathrm{min}}$  small for all the experiments we simulated, it actually decreases as we increase  $m$ . Despite proving successful for all the interferometers we implemented experimentally, our numerical simulations reveal that the test fails for some interferometers if the ratio  $m / n$  is too low.

In the probed experimental regime it is possible to perform a full validation of the boson sampling experiments by reconstructing all probabilities associated with no-collision events. This requires experimental data sets of a larger size to be recorded; for the  $m = 7$  chip, for example, we recorded  $\sim 2,100$  events. The experimentally reconstructed probabilities are then compared with the theoretical prediction<sup>1</sup> based on the theoretical unitary  $U$ . The results are reported in Fig. 3, and show good agreement between the experiments and the predictions. In Supplementary Section 'Experimental output distributions' we provide details on other figures of merit for the quality of our manufacturing technique. Furthermore, we have also applied the Aaronson-Arkhipov test<sup>8</sup> to the full data set (Fig. 3d-g), showing how the confidence in the test results increases monotonically with sample size.

In addition, we experimentally test another protocol to validate boson sampling data against arbitrary probability distributions, including those that exploit information on the unitary  $U$ . One possible way of cheating is to use distinguishable

photons, instead of indistinguishable ones, as input to the unitary  $U$ . The former do not undergo multiphoton interference and can be mimicked by a set of independent single-photon experiments or simulated in a classically efficient way. In the Methods such a protocol is described, based on a standard likelihood ratio test[27]. We applied the test to successfully discriminate boson sampling experiments performed with either indistinguishable or distinguishable photons in interferometers with 7, 9 and 13 modes (Fig. 4). The regime of distinguishable photons was obtained experimentally by introducing a relative temporal delay between the three photons that is longer than their coherence time.

The likelihood ratio test requires calculation of only the probabilities associated with the observed outcomes. As we will discuss in the following, the number of observed outcomes that is necessary to achieve the desired discrimination confidence is exponentially smaller than the total number of possible outcomes (whose probabilities should be calculated for a full simulation of the output distribution). This test can therefore be used in an experimental regime that is non-trivial to simulate classically. To date, no boson sampling simulation algorithm is known that is significantly faster than computing the full output probability distribution, which requires an exponential number of permanents to be calculated. According to our simulations (Fig. 4d; see Supplementary Section 'Validation against distinguishable sampler'), the required number of observed outcomes for discriminating between a distinguishable sampler and a boson sampler with success rate  $>95\%$  is almost constant and is  $<100$  measurements. The number of permanents that need to be calculated for a full simulation of the output distribution, on the other hand, scales as  $\binom{m}{n}$ . This means that, in the absence of

further theoretical progress, there is a de facto exponential gap between the computational complexities of validation and simulation. As an illustration, an experiment with  $n = 8$  photons interfering in a 100-mode interferometer could be validated by calculating  $\sim 100$  permanents, which, on a current standard laptop, requires  $\sim 10$  ms. The brute-force simulation, on the other hand, would involve the calculation of  $\sim 1 \times 10^{11}$  permanents of  $8 \times 8$  matrices, which would require  $\sim 8$  months. This (conjectured) gap between the complexities of simulation and validation could help guide the design of future boson sampling devices whose functioning, despite being non-trivial to simulate, can be feasibly validated against many alternative explanations.

Our results provide experimental support for the recent refutation<sup>8</sup> of a criticism of boson sampling experiments<sup>7</sup>. We have also shown the feasibility of certifying boson sampling experiments against various alternative hypotheses. This will be decisive in future experiments that use boson sampling devices to establish the quantum information processing supremacy over classical computers. Another approach, based on Fourier matrices, for the validation of boson sampling experiments against alternative distributions has been recently proposed<sup>28</sup>.

Note added in proof: After completion of this manuscript, a paper on the experimental verification of quantum complexity in linear optics was reported online $^{29}$ .

# Methods

Fabrication. Multimode integrated interferometers were fabricated in glass chips by femtosecond laser writing $^{20,21}$  with a layout as described in refs 2 and 26. To inscribe the waveguides, laser pulses with  $220~\mathrm{nJ}$  energy and  $1\mathrm{MHz}$  repetition rate from an Yb:KYW cavity dumped oscillator were focused through a 0.6 NA microscope objective  $170~{\mu\mathrm{m}}$  under the sample surface. The laser pulses were  $\sim 300$  fs long with a wavelength of  $1,030~\mathrm{nm}$ . The sample was translated at constant speed, drawing in the three dimensions the desired waveguide paths into the boro-aluminosilicate glass (EAGLE2000, Corning). The fabricated waveguides yielded single-mode behaviour at a wavelength of  $800~\mathrm{nm}$ , with propagation losses of  $\sim 0.5\mathrm{dBcm}^{-1}$ .

The architecture of the interferometers is shown in Fig. 1b. The  $m = 5$  device corresponds to a Haar-random unitary, and was implemented by decomposing the unitary in beamsplitter operations and phase shifters according to the procedure shown in ref. 22. The  $m = 7, 9, 13$  interferometers were obtained by drawing a set of random phases, and by implementing the corresponding network with balanced 50/50 directional couplers.

Experimental set-up. Four photons were produced in the pulsed regime at  $785~\mathrm{nm}$  by exploiting the second-order parametric downconversion process and pumping a 2-mm-long  $\beta$ -barium borate (BBO) crystal with the  $392.5\mathrm{-nm}$ -wavelength pump field. Typical count rates for the source were  $\sim 250,000\mathrm{Hz}$  for the four signals,  $40,000\mathrm{Hz}$  for the twofold coincidences and  $20\mathrm{Hz}$  for the fourfold coincidences. One of the photons, adopted as a trigger, was filtered by  $3\mathrm{nm}$  interferential filters, coupled into a single-mode fibre, and detected by a single-photon counting detector. For the other three photons, spectral filtering by  $3\mathrm{nm}$  interferential filters, coupling into single-mode fibres, polarization compensation and propagation through different delay lines were performed before coupling into the chips. At the output of the chip, multimode fibres were connected to single-photon counting detectors. The fourfold coincidences between the three-photon state and the trigger signal were acquired by an electronic system (see Supplementary Fig. 1 and Supplementary Section 'Experimental apparatus, generated state and six-photon contributions' for more details).

Validation test of Aaronson and Arkhipov. Let us assume that the  $n$  input photons occupy the set of modes  $S = \{s_1, s_2, \ldots, s_n\}$  of the  $m$ -mode interferometer, which is described by an  $m \times m$  unitary matrix  $U$ . Each single experimental outcome consists of photons leaving the interferometer in a set of modes  $T = \{t_1, t_2, \ldots, t_n\}$ , where we have assumed an experiment that only detects no-collision events. Define an  $n \times n$  submatrix  $A$  of  $U$  with elements  $A_{i,j} = U_{s_i,t_j}$ . Now calculate the estimator  $P = \prod_{i=1}^{n} \sum_{j=1}^{n} |A_{i,j}|^2$ .  $P$  was shown to be correlated with the boson sampler probability associated with that event. Intuitively, we expect to observe more high-probability than low-probability events, so the idea is to compare each event's probability (or, rather, its efficiently computable estimator  $P$ ) with what would be expected if the output distribution were uniform. The test decides the outcome is more likely to arise from boson sampling if  $P > (n/m)^n$ , otherwise the outcome is assigned to the uniform distribution. The value  $(n/m)^n$  is associated with the normalization of  $P$ . Notably, the test is computationally efficient; in particular, it does not involve the calculation of any permanents. Assuming the interferometer's unitary is picked from the uniform, Haar distribution, this test has

been proven to succeed with probability $^{8}$ $1 - O(\delta)$  and for sufficiently large  $n$ , provided  $m > n^{5.1} / \delta$ . To increase the success rate, the process is repeated with a sample of  $N_{\mathrm{set}}$  experimental outcomes and majority voting is used to decide which case is more likely to hold.

Validating boson sampling data against distinguishable photon distribution. The test to validate boson sampling data against the hypothesis that the photons are distinguishable is an adapted version of the likelihood ratio test $^{27}$ , which incorporates a discrimination threshold to compensate for experimental noise. Let  $p_i^{\mathrm{ind}}$  and  $q_i^{\mathrm{dis}}$  be the probabilities associated with indistinguishable and distinguishable photons for the measured outcome, and let  $D$  be the discrimination parameter, initialized to the value  $D = 0$ . For each experimental outcome, we calculate the ratio of the expected probabilities for indistinguishable and distinguishable photons. If the ratio is close to one, up to a threshold  $k_1 < p_i^{\mathrm{ind}} / q_i^{\mathrm{dis}} < 1 / k_1$ , the event is considered to be inconclusive and  $D$  is left unchanged. These inconclusive events, however, are still counted as a resource and do contribute to the effective number of events required to discriminate the two distributions. If  $1 / k_1 \leq p_i^{\mathrm{ind}} / q_i^{\mathrm{dis}} < k_2$ , the event is assigned to the boson sampler by adding  $+1$  to  $D$ . If the ratio between the two probabilities is high,  $p_i^{\mathrm{ind}} / q_i^{\mathrm{dis}} \geq k_2$ , the event is assigned to the boson sampler by adding  $+2$  to  $D$ , thus reflecting the higher level of confidence in this case. Conversely, if  $1 / k_2 < p_i^{\mathrm{ind}} / q_i^{\mathrm{dis}} \leq k_1$  and  $p_i^{\mathrm{ind}} / q_i^{\mathrm{dis}} \leq 1 / k_2$  the event is assigned to the distinguishable sampler by adding  $-1$  and  $-2$  to  $D$ , respectively. Finally, after  $N$  experimental outcomes, if  $D > 0$  the whole data set is assigned to the boson sampler and conversely if  $D < 0$ . In our analysis we set  $k_1 = 0.9$  and  $k_2 = 1.5$ .

Received 17 December 2013; accepted 19 May 2014; published online 22 June 2014

# References

1. Aaronson, S. & Arkhipov, A. in Proceedings of the 43rd Annual ACM Symposium on Theory of Computing (eds Fortnow, L. & Vadhan, S.) 333-342 (ACM Press, 2011).  
2. Crespi, A. et al. Integrated multimode interferometers with arbitrary designs for photonic boson sampling. Nature Photon. 7, 545-549 (2013).  
3. Tillmann, M. et al. Experimental boson sampling. Nature Photon. 7, 540-544 (2013).  
4. Broome, M. A. et al. Photonic boson sampling in a tunable circuit. Science 339, 794-798 (2013).  
5. Spring, J. B. et al. Boson sampling on a photonic chip. Science 339, 798-801 (2013).  
6. Barz, S., Fitzsimons, J. F., Kashefi, E. & Walther, P. Experimental verification of quantum computation. Nature Phys. 9, 727-731 (2013).  
7. Gogolin, C., Kliesch, M., Aolita, L. & Eisert, J. Boson-sampling in the light of sample complexity. Preprint at http://lanl.arxiv.org/abs/1306.3995 (2013).  
8. Aaronson, S. & Arkhipov, A. Bosonsampling is far from uniform. Preprint at http://lanl.arxiv.org/abs/1309.7460 (2013).  
9. Shor, P. W. Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer. SIAM J. Comput. 26, 1484-1509 (1997).  
10. Ladd, T. D. et al. Quantum computers. Nature 464, 45-53 (2010).  
11. Barreiro, J. T. et al. An open-system quantum simulator with trapped ions. Nature 470, 486-491 (2011).  
12. Islam, R. et al. Emergence and frustration of magnetism with variable-range interactions in a quantum simulator. Science 340, 583-587 (2013).  
13. Preskill, J. Quantum computing and the entanglement frontier. Preprint at http://lanl.arxiv.org/abs/1203.5813 (2012).  
14. Rohde, P. P. & Ralph, T. C. Error tolerance of the boson-sampling model for linear optics quantum computing. Phys. Rev. A 85, 022332 (2012).  
15. Leverrier, A. & Garcia-Patrón, R. Does boson sampling need fault-tolerance? Preprint at http://lanl.arxiv.org/abs/1309.4687 (2013).  
16. Motes, K. R., Dowling, J. P. & Rohde, P. P. Spontaneous parametric downconversion photon sources are scalable in the asymptotic limit for bosonsampling. Phys. Rev. A 88, 063822 (2013).  
17. Rohde, P. P., Motes, K. R. & Dowling, J. P. Sampling generalized cat states with linear optics is probably hard. Preprint at http://lanl.arxiv.org/abs/1310.0297 (2013).  
18. Shen, C., Zhang, Z. & Duan, L.-M. Scalable implementation of boson sampling with trapped ions. Phys. Rev. Lett. 112, 050504 (2014).  
19. Davis, K. M., Miura, K., Sugimoto, N. & Hirao, K. Writing waveguides in glass with a femtosecond laser. Opt. Lett. 21, 1729-1731 (1996).  
20. Osellame, R. et al. Femtosecond writing of active optical waveguides with astigmatically shaped beams. J. Opt. Soc. Am. B 20, 1559-1567 (2003).  
21. Gattass, R. & Mazur, E. Femtosecond laser micromachining in transparent materials. Nature Photon. 2, 219-225 (2008).  
22. Reck, M., Zeilinger, A., Bernstein, H. J. & Bertani, P. Experimental realization of any discrete unitary operator. Phys. Rev. Lett. 73, 58-61 (1994).  
23. Sansoni, L. et al. Two-particle bosonic-fermionic quantum walk via integrated photonics. Phys. Rev. Lett. 108, 010502 (2012).

24. Crespi, A. et al. Anderson localization of entangled photons in an integrated quantum walk. Nature Photon. 7, 322-328 (2013).  
25. Spagnolo, N. et al. Three-photon bosonic coalescence in an integrated tritter. Nature Commun. 4, 1606 (2013).  
26. Spagnolo, N. et al. General rules for bosonic bunching in multimode interferometers. Phys. Rev. Lett. 111, 130503 (2013).  
27. Cover, T. M. & Thomas, J. A. in Elements of Information Theory 2nd edn, Ch. 12 (Wiley-Interscience, 2006).  
28. Tichy, M. C., Mayer, K., Buchleitner, A. & Mølmer, K. Stringent and efficient assessment of boson-sampling devices. Preprint at http://lanl.arxiv.org/abs/1312.3080 (2013).  
29. Carolan, J. et al. On the experimental verification of quantum complexity in linear optics. Preprint at http://lanl.arxiv.org/abs/1311.2913v2 (2013).

# Acknowledgements

The authors acknowledge feedback from S. Aaronson, A. Arkhipov, L. Aolita and J. Eisert. This work was supported by the European Research Council (ERC-Starting Grant 3D-QUEST, 3D-Quantum Integrated Optical Simulation, grant agreement no. 307783, http://www.3dquest.eu), by Progetto d'Ateneo SUPERCONTINUUM (Generation and Characterization of Supercontinuum Laser Sources for Bio-spectroscopy and Quantum

Optics), by PRIN (Programmi di ricerca di rilevante interesse nazionale) project AQUASIM (Advanced Quantum Simulation and Metrology) and by the Brazilian National Institute for Science and Technology of Quantum Information (INCT-IQ/CNPq).

# Author contributions

N.S., C.V., M.B., D.J.B., P.M., R.O., E.F.G. and F.S. conceived the experimental approach for the validation of boson sampling. A.C., R.R. and R.O. fabricated and characterized the integrated devices using classical optics. N.S., C.V., M.B., F.F. and F.S. carried out the quantum experiments. S.G. and G.M. developed the data acquisition system. N.S., C.V., M.B., D.J.B., P.M., E.F.G. and F.S. elaborated the data. All authors discussed the experimental implementation and results, and contributed to writing the paper.

# Additional information

Supplementary information is available in the online version of the paper. Reprints and permissions information is available online at www.nature.com/reprints. Correspondence and requests for materials should be addressed to R.O., E.F.G. and F.S.

# Competing financial interests

The authors declare no competing financial interests.