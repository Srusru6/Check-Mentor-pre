This copy is for your personal, non-commercial use only.

If you wish to distribute this article to others, you can order high-quality copies for your colleagues, clients, or customers by clicking here.

Permission to republish or repurpose articles or portions of articles can be obtained by following the guidelines here.

The following resources related to this article are available online at www.sciencemag.org (this information is current as of August 9, 2012):

Updated information and services, including high-resolution figures, can be found in the online version of this article at:

http://www.sciencemag.org/content/309/5741/1704.full.html

Supporting Online Material can be found at:

http://www.sciencemag.org/content/suppl/2005/09/06/309.5741.1704.DC1.html

This article has been cited by 40 article(s) on the ISI Web of Science

This article has been cited by 4 articles hosted by HighWire Press; see:

http://www.sciencemag.org/content/309/5741/1704.full.html#related-urls

This article appears in the following subject collections:

Chemistry

http://www.sciencemag.org/cgi/collection/chemistry

the nanohelix perpendicular to its axial direction, has been measured by AFM with use of the force-displacement  $(F - Z)$  curve (17). Through the static compression of a nanohelix lying on a silicon substrate with an AFM tip (Fig. 4B) (fig. S5) and careful calibration of the sensitivity,  $S$ , of the photodetector (11, 18), which is the inverse of the slope of the  $F - Z$  curve (fig. S6), the transverse spring constant of the nanohelix,  $K_{\mathrm{Helix}}$ , was found to be (11) 3.9, 4.6, 4.5, and  $5.3~\mathrm{N / m}$  for one to four turns, respectively, of the nanohelix as labeled in Fig. 4B. The measured  $K_{\mathrm{Helix}}$  is near the theoretically estimated transverse spring constant of  $4.2~\mathrm{N / m}$  (11), and so the elastic modulus, E, values of the nanohelix derived from the measured spring constant (11) are 42, 49, 48, and  $57~\mathrm{GPa}$  for the four turns, respectively, which agrees well with the elastic modulus measured for straight  $\mathrm{ZnO}$  nanobelts by mechanical resonance with the use of in situ TEM (19).

The perfect helix we observed is of great interest not only for understanding the growth behavior of polar-surface-driven growth processes in the wurtzite system, such as GaN, AlN, and InN, but also for investigating fundamental physics and optical phenomena. The piezoelectric and semiconducting properties of  $\mathrm{ZnO}$  suggest that the nanohelix could be a fundamental unit for investigating electromechanically coupled nanodevices by using the

superlattice piezoelectric domains. The nanohelix is likely to have important applications in sensors, transducers, resonators, and photonics.

# References and Notes

1. S. Amelinckx et al., Science 265, 635 (1994).  
2. R. P. Gao, Z. L. Wang, S. S. Fan, J. Phys. Chem. B 104, 1227 (2000).  
3. H. F. Zhang, C. M. Wang, E. C. Buck, L. S. Wang, Nano Lett. 3, 577 (2003).  
4. H. F. Zhang, C. M. Wang, L. S. Wang, Nano Lett. 2, 941 (2002).  
5. O. G. Schmidt, K. Eberl, Nature 410, 168 (2001).  
6. X. Y. Kong, Z. L. Wang, Nano Lett. 3, 1625 (2003).  
7. X. Y. Kong, Y. Ding, R. Yang, Z. L. Wang, Science 303, 1348 (2004).  
8. W. L. Hughes, Z. L. Wang, J. Am. Chem. Soc. 126, 6703 (2004).  
9. Z. L. Wang et al., Adv. Funct. Mater. 14, 944 (2004).  
10. Z. W. Pan, Z. R. Dai, Z. L. Wang, Science 291, 1947 (2001).  
11. See Materials and Methods provided on Science Online.  
12. The  $\{\bar{1}\bar{1} 22\}$  are typical twin planes for ZnO (20).  
13. P. X. Gao, Z. L. Wang, Small, in press; published online (http://dx.doi.org/10.1002/smll.200500165).  
14. The growth of the nanostructure occurred at a local temperature of  $\sim 700^{\circ}$  to  $800^{\circ}\mathrm{C}$  in an argon atmosphere, under which the possibility of neutralizing the surface polar charges by adsorbing foreign molecules is unlikely, provided the growth occurred fairly quickly. This result is consistent with our previous studies [see (7-9)].  
15. From the energy point of view, a polar-surface-dominated nanobelt tends to fold itself into a ring or spring for reducing electrostatic energy (6). The nanoring is stable if the ratio between nanobelt thickness,  $t$ , and the radius,  $R$ , of the nanoring is smaller than  $\sim 3\%$  (8). Nanorings with  $t / R > 3\%$  are energetically unfavorable to form.

16. The aforementioned data rule out the possibility that the nanohelix is formed by bilayer surface strain (5) for two reasons. First, there is no bilayer strained structure in our system; and second, the difference in surface stress on the (0001)-Zn and (0001)-O of ZnO, if any, has negligible effect on the formation of nanorings or nanobows (8). The nanohelix is likely to be formed by two processes: the rigid structural alteration due to the formation of the superlattice and the spontaneous polar-charge-induced bending (6). However,  $t$  of the nanobelt is  $\sim 20\mathrm{nm}$ , and typical  $R$  of the nanohelix is  $\sim 150$  to  $350\mathrm{nm}$  (Fig. 1). Thus the  $t/R$  is  $\sim 6$  to  $13\%$ , which is much larger than the threshold value ( $\sim 3\%$ ) permitted for forming a nanoring by electrostatic polar charges (15). Also, considering the great reduction in area of the polar surfaces (for  $\sim 50\%$ ) after forming the superlattice as well as the helical shape of the structure, the role played by polar charges in forming a helix is dramatically reduced. Therefore, the dominant mechanism for forming the nanohelix is by rigid lattice rotation and twisting as a result of superlattice formation.  
17. E.W. Wong, P.E. Sheehan, C.M. Lieber, Science 277, 1971 (1997).  
18. A. Volodin et al., Phys. Rev. Lett. 84, 3342 (2000).  
19. X. D. Bai, P. X. Gao, Z. L. Wang, E. G. Wang, Appl. Phys. Lett. 82, 4806 (2003).  
20. Y. Dai, Y. Zhang, Z. L. Wang, Solid State Commun. 126, 629 (2003).  
21. Thanks to support from NSF, the NASA Vehicle Systems Program and Department of Defense Research and Engineering, the Defense Advanced Research Projects Agency, and the Chinese Academy of Sciences.

# Supporting Online Material

www.sciencemag.org/cgi/content/full/309/5741/1700/DC1

Materials and Methods

Figs. S1 to S6

23 June 2005; accepted 2 August 2005

10.1126/science.1116495

# Simulated Quantum Computation of Molecular Energies

Alán Aspuru-Guzik, $^{1*}$ † Anthony D. Dutoi, $^{1*}$  Peter J. Love, $^{2}$  Martin Head-Gordon $^{1,3}$

The calculation time for the energy of atoms and molecules scales exponentially with system size on a classical computer but polynomially using quantum algorithms. We demonstrate that such algorithms can be applied to problems of chemical interest using modest numbers of quantum bits. Calculations of the water and lithium hydride molecular ground-state energies have been carried out on a quantum computer simulator using a recursive phase-estimation algorithm. The recursive algorithm reduces the number of quantum bits required for the readout register from about 20 to 4. Mappings of the molecular wave function to the quantum bits are described. An adiabatic method for the preparation of a good approximate ground-state wave function is described and demonstrated for a stretched hydrogen molecule. The number of quantum bits required scales linearly with the number of basis functions, and the number of gates required grows polynomially with the number of quantum bits.

Feynman observed that simulation of quantum systems might be easier on computers using quantum bits (qubits) (1). The subsequent development of quantum algorithms has made this observation concrete (2-6). On classical computers, resource requirements for complete simulation of the time-independent Schrödinger equation scale exponentially with the number of atoms in a molecule, limiting

such full configuration interaction (FCI) calculations to diatomic and triatomic molecules (7). Computational quantum chemistry is therefore based on approximate methods that often succeed in predicting chemical properties for larger systems, but their level of accuracy varies with the nature of the species, making more complete methods desirable (8).

Could quantum computation offer a new way forward for exact methods? Despite the formal promise, it has not been demonstrated that quantum algorithms can compute quantities of chemical importance for real molecular systems to the requisite accuracy. We address this issue by classically simulating quantum computations of the FCI ground-state energies of two small molecules. Although the basis sets used are small, the energies are obtained to the precision necessary for chemistry. Absolute molecular energies must be computed to a precision (greater than six decimal places) that reflects the smaller energy differences observed in chemical reactions  $(\sim 0.1\mathrm{kcal / mol})$ . These simulations show that quantum computers of tens to hundreds of qubits can match and exceed the capabilities of classical FCI calculations.

A molecular ground-state energy is the lowest eigenvalue of a time-independent Schrödinger equation. The phase-estimation algorithm (PEA) of Abrams and Lloyd  $(3,4)$  can

$^{1}$ Department of Chemistry, University of California, Berkeley, CA, USA.  $^{2}$ D-Wave Systems, Inc., 4401 Still Creek Drive, Suite 100, Burnaby, BC V5C 6G9, Canada.  $^{3}$ Chemical Sciences Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA.

*These authors contributed equally to this work.  
†To whom correspondence should be addressed.  
E-mail: alan@aspuru.com

be used to obtain eigenvalues of Hermitian operators; we address issues concerning its implementation for molecular Hamiltonians. The molecular ground-state wave function  $|\Psi \rangle$  is represented on a qubit register S (state). Another register R (readout) is used to store intermediate information and to obtain the Hamiltonian eigenvalue  $E$ . The Hamiltonian  $\hat{H}$  is used to generate a unitary operator  $\hat{U}$ , with  $E$  mapped to the phase of its eigenvalue  $e^{i2\pi \phi}$ .

$$
\hat {U} | \Psi \rangle = e ^ {i \hat {H} \tau} | \Psi \rangle = e ^ {i 2 \pi \phi} | \Psi \rangle ; E = 2 \pi \phi / \tau \tag {1}
$$

Through repeated controlled action of powers of  $\hat{U}$ , the computer is placed in the state

$$
\left| \mathbf {R} \right\rangle \otimes \left| \mathbf {S} \right\rangle = \left(\sum_ {n} e ^ {(i 2 \pi \phi) n} | n \rangle\right) \otimes \left| \Psi \right\rangle \tag {2}
$$

The summation index  $n$  enumerates the basis states of  $\mathbf{R}$  according to their bit-string value. The quantum inverse Fourier transform is then applied to  $\mathbf{R}$  to obtain an approximation to  $\phi$  written in binary to  $\mathbf{R}$ . The procedure is related to the Fourier transform of the time dependence of an eigenstate to obtain its eigenenergy. By using polynomially scaling classical approximation methods, an initial estimate of  $E$  can be obtained to choose  $\tau$  such that  $0 \leq (\phi \approx 1/2) < 1$ .

We address four separate issues. First, we show how standard chemical basis sets can be used for representations of the wave function on S. Second, although the size of R relative to S will be marginal in the large-system limit, this initial overhead (20 qubits for a chemically meaningful result) presently represents a substantial impediment to both classical simulation and actual implementation of the algorithm. We show how a modification of the PEA makes it possible to perform a sequence of computations with a smaller register, such that the precision of the result obtained is independent of the size of R. Third, the algorithm requires that any estimated ground state has a large overlap with the actual eigenstate. We show how a good estimate of the ground-state wave function may be prepared adiabatically from a crude starting point. Finally,  $\hat{U}$  must be represented in a number of quantum gates that scales polynomially with the size of the system, and we give such bounds.

Any implementation of a quantum-simulation algorithm requires a mapping from the system wave function to the state of the qubits. Basis-set methods of quantum chemistry often represent many-particle molecular wave functions in terms of single-particle atomic orbitals. The number of orbitals in a basis set is proportional to the number of atoms in a molecule. The molecular wave function may be represented by a state of S in two basic ways. In the direct mapping, each qubit represents the fermionic occupation state of a particular atomic orbital,

occupied or not. In this approach, a Fock space of the molecular system is mapped onto the Hilbert space of the qubits. This mapping is the least efficient but has advantages discussed later. In the more efficient compact mapping, only a subspace of the Fock space with fixed electron number is mapped onto the qubits. The states of the simulated system and of the qubit system are simply enumerated and equated. Furthermore, one could choose only a subspace of the fixed-particle-number space. The compact mapping with restriction to a spin-state subspace is the most economical mapping considered in this work. Figure 1 shows that the number of qubits required for both the compact and direct mappings scales linearly with the number of basis functions. Also shown are the qubit requirements for specific molecules with different basis sets and mappings. More exten

sive qubit estimates for computations on  $\mathrm{H}_2\mathrm{O}$  are given in Table 1, including restriction to the singlet-spin subspace.

In this work, a modified PEA was carried out, which uses a relatively small number of qubits in  $\mathbf{R}$  (as few as four for stability). This implementation allows more of the qubits to be devoted to information about the system and decreases the number of consecutive coherent quantum gates necessary. This procedure can be interpreted as making continually better estimates of a reference energy. The Hamiltonian is then shifted by the current reference energy and an estimate of the deviation of the actual energy from the reference is computed. The reference energy is then updated, and the procedure is repeated until the desired precision is obtained.

The algorithm at iteration  $k$  is illustrated in Fig. 2A. In iteration zero, we set  $\hat{V}_0 = \hat{U}$  and

![](images/99217f617bdeb62ab6916682a881e0874357b03a7a4c18144c0712be915268b6.jpg)  
Fig. 1. Qubit requirements versus basis size. The number of qubits required to store the wave function of a molecule is shown as a function of the number of basis functions for different mappings. For the compact mapping, the qubit requirement depends also on the ratio of number of electrons to basis functions, which is relatively constant for a given basis set; although the higher quality cc-pVTZ basis is more economical per basis function, a molecule in this basis uses substantially more functions than with the 6-31G* basis. The qubits required for specific molecules and basis sets are also shown.

Table 1. Qubit requirements for computations on water. The number of qubits needed to store the wave function of water is given for various basis sets and system-qubit mappings, including restriction to the singlet-spin subspace.  

<table><tr><td>Water</td><td colspan="3">Basis set (number of functions)</td></tr><tr><td>Mapping</td><td>STO-3G (7)</td><td>6-31G* (19)</td><td>cc-pVTZ (58)</td></tr><tr><td>Compact (singlets)</td><td>8</td><td>25</td><td>42</td></tr><tr><td>Compact</td><td>10</td><td>29</td><td>47</td></tr><tr><td>Direct</td><td>14</td><td>38</td><td>116</td></tr></table>

![](images/f08e4634379f870dc7f6e083aaef9f5dfaf698da870f9365adead5ab3965c955.jpg)

![](images/54977835008da40f2667fad0a8c821e78de3ba4c45360c6e303aa4cb84fc1625.jpg)  
Fig.2. Recursive PEA circuit and output. (A) The quantum circuit for the recursive phase-estimation algorithm is illustrated.  $k$  iterations are required to obtain  $k$  bits of a phase  $\phi$  that represents the molecular energy.  $QFT^{+}$ represents the quantum inverse Fourier transform and  $Hd$  is a Hadamard gate; the dial symbols represent measurement. (B) Output probabilities for obtaining the first eight bits of  $\phi$  in the water calculation are shown. The abscissa is scaled to be in terms of molecular energy, and the ordinate is probability.

![](images/e4b12cfa3006f426dde6889a507442a0e5a4a16136e40a34c338450f811f4864.jpg)  
Fig. 3. ASP evolution of ground-state overlap and excitation gap. (A) Time evolution of the squared overlap of the wave function  $|\Psi_{\mathrm{ASP}} \rangle$  with the exact ground state  $|\Psi \rangle$  during adiabatic state preparation is shown. The system is the hydrogen molecule at different nuclear separations  $r$ ; time was divided into 1000 steps in all cases. (B) Time evolution of the singlet ground- to first-excited-state energy gap of the Hamiltonian used along the adiabatic path is shown.

![](images/1bec68348dfd4b5c31f39207bd265d70add8bb25a01c10b0ef3b00243e7a24e3.jpg)

perform a four-qubit PEA on  $\hat{V}_0$ . This estimates  $\phi$  on the interval zero to unity with a precision of 1/16. We use this estimate to construct a shift  $\phi_0$ , which is a lower bound on  $\phi$ . We apply this shift and repeat the four-qubit PEA using the new operator  $\hat{V}_1 = \left[e^{-i2\pi \phi_0}\hat{V}_0\right]^2$ . This determines the remainder of  $\phi$  above the previous lower bound on an interval representing half of the previous interval. In each subsequent iteration  $k$ , we construct a similarly modified operator  $\hat{V}_k$  and shift  $\phi_k$ . By choosing a  $\phi_k$  that is one-fourth lower than the phase of the  $\hat{V}_k$  eigenvalue estimate, we ensure that the phase of the  $\hat{V}_{k + 1}$  eigenvalue is approximately centered on the interval zero to unity. In each iteration, we therefore obtain one additional bit of  $\phi$ , as shown in Fig. 2B for a calculation on  $\mathrm{H}_2\mathrm{O}$ .

To demonstrate the usefulness of the recursive procedure, we carried out calculations on  $\mathrm{H}_2\mathrm{O}$  and LiH. For  $\mathrm{H}_2\mathrm{O}$ , we used the minimal STO-3G basis set, yielding 196 singlet-spin configurations; there are 1210 such configurations for LiH in the larger 6-31G basis. This required 8 and 11 qubits, respectively, for the compact mapping of the singlet subspace. Register S was initialized to the Hartree-Fock (HF) wave function in both cases. After 20 iterations, the electronic energy obtained for  $\mathrm{H}_2\mathrm{O}$  [-84.203663 atomic units (a.u.)] matched the Hamiltonian diagonalization energy (-84.203665 a.u.). The LiH calculation (-9.1228936 a.u.) matched diagonalization (-9.1228934 a.u.) to the same number of significant digits. The precision is good enough for almost all chemical purposes. The discrepancy between the PEA and diagonalization is attributed to error in matrix exponentiation to form  $\hat{U}$  from  $\hat{H}$ .

In the simulations described above, the approximation to the ground-state wave function was the HF state  $|\Psi^{\mathrm{HF}}\rangle$ . The probability of observing the exact ground state  $|\Psi \rangle$ , and hence the success of the PEA, is then proportional to  $|\langle \Psi |\Psi^{\mathrm{HF}}\rangle |^2$ . However, it is known for some cases, such as molecules close to the dissociation limit or in the limit of large system size, that the HF wave function has vanishing overlap with the ground state (9). The overlap of the initially prepared state with the exact state can be systematically improved by an adiabatic-state-preparation (ASP) algorithm, relying on the adiabatic theorem (10-12). The theorem states that a system will remain in its ground state if the Hamiltonian is changed slowly enough. Our Hamiltonian is changed slowly by discretized linear interpolation from the trivial HF case to the FCI operator. The efficiency is governed by how rapidly the Hamiltonian may be varied, which is determined by the gap between ground-state and first-excited-state energies along the path (11). In the case of quantum chemistry problems, lower bounds on this gap may be estimated with conventional methods.

The path  $\hat{H}^{\mathrm{HF}}\rightarrow \hat{H}$  is chosen by defining  $\hat{H}^{\mathrm{HF}}$  to have all matrix elements equal to zero, except the first element, namely  $H_{1,1}$ , which is equal to the HF energy. This yields an initial gap the size of the ground-state mean-field energy, which is very large relative to typical electronic excitations. The ASP method was applied to the  $\mathrm{H}_{2}$  molecule at large separations in the STO-3G basis, for which the squared overlap of the HF wave function with the exact ground state is one half. As evidenced by Fig. 3A, the ASP algorithm prepares states with a high squared overlap for several internuclear distances of the  $\mathrm{H}_{2}$  molecule. Figure 3B plots the relevant gap along the adiabatic path, which is shown for this system to be well-behaved and nonvanishing.

The accuracy and quantum-gate complexity of the algorithm depend on the specific gate decomposition of the unitary operators  $\hat{V}_k$ , defined above. The factorization of unitary matrices into products of one- and two-qubit elementary gates is the fundamental problem of quantum circuit design. We now demonstrate that the lengths of the gate sequences involved are bounded from above by a polynomial function of the number of qubits.

We analyze the gate complexity of our  $\hat{U}$  for the direct mapping of the state. The molecular Hamiltonian is written in second quantized form as

$$
\begin{array}{l} \hat {H} = \sum_ {X} \hat {h} _ {X} = \sum_ {p, q} \langle p | \hat {T} + \hat {V} _ {N} | q \rangle \hat {a} _ {p} ^ {+} \hat {a} _ {q} - \\ \frac {1}{2} \sum_ {p, q, r, s} \langle p | \langle q | \hat {V _ {e}} | r \rangle | s \rangle \hat {a} _ {p} ^ {+} \hat {a} _ {q} ^ {+} \hat {a} _ {r} \hat {a} _ {s} \tag {3} \\ \end{array}
$$

where  $|p\rangle$  is a one-particle state,  $\hat{a}_p$  is its fermionic annihilation operator, and  $\hat{T},\hat{V}_N,$  and  $\hat{V_e}$  are the one-particle kinetic and nuclear-attraction operators and the two-particle electronrepulsion operator, respectively. It has been shown in (2), that for the following approximation to  $\hat{U}$

$$
e ^ {i \hat {H} \tau} \approx \left[ \prod_ {X} e ^ {i \hat {h} _ {X} \frac {\tau}{M}} \right] ^ {M} \tag {4}
$$

$M$  can always be chosen such that the error is bounded by some preset threshold. The number of gates to implement  $\hat{U}$  then scales polynomially with the system size for a given  $M$ , under the conditions that the number of terms  $\hat{h}_x$  scales polynomially with system size and that each  $\hat{h}_x$  acts on a polynomially scaling number of qubits. In our case, these conditions are manifestly fulfilled. The number of terms in the Hamiltonian grows approximately with the fourth power of the number of atoms, and each term involves maximally four basis functions, implying action on at most five qubits in the direct mapping (four qubits in S plus a control qubit in R). A linear-scaling number of two-qubit operations (similar to qubit swaps) can

account for fermionic antisymmetry in the action of the unitary operator constructed from each  $\hat{h}_X$  (13).  $M$  is a multiplicative factor in the number of gates. Because the fraction of all pairs of  $\hat{h}_X$  terms that do not commute decreases with system size, it is reasonable to assume that  $M$  increases polynomially at worst. The advantage of the direct mapping is that, at most, controlled four-qubit unitary operations are required. The number of one- and two-qubit elementary gates required to represent an arbitrary four-qubit gate has been shown to be always less than 400 (14); the structure of a controlled four-qubit unitary operation will allow a decomposition into a similar order of magnitude in the number of gates.

We have found that chemical precision can be achieved with modest qubit requirements for the representation of the wave function and for the readout register. The ASP algorithm has been shown to systematically improve the probability of success of the PEA. Although exponentially difficult on a classical computer, extension to larger molecules requires only linear growth in the number of qubits. The direct mapping for the molecular wave function to the qubit state allows the unitary operator to be decomposed into a number of gates that scales polynomially with system size.

The difficulty of performing quantumcomputing simulations is about an order of magnitude greater than conventional FCI. Although possible as experiments, such simulations are not a competitive alternative. To repeat the calculations performed here with a high-quality basis set (cc-pVTZ) would require S to consist of 47 or 22 qubits for  $\mathrm{H}_2\mathrm{O}$  or LiH,

respectively, using the compact mapping of the full Hilbert space. For most molecules and basis set combinations shown in Fig. 1, an FCI calculation is certainly classically intractable. An FCI calculation for  $\mathrm{H}_2\mathrm{O}$  with cc-pVTZ would be at the edge of what is presently possible. This demonstrates an often-stated conjecture, that quantum simulation algorithms with 30 to 100 qubits will be among the smallest applications of quantum computing that can exceed the limitations of classical computing.

# References and Notes

1. R. P. Feynman, Int. J. Theor. Phys. 21, 467 (1982).  
2. S. Lloyd, Science 273, 1073 (1996).  
3. D. S. Abrams, S. Lloyd, Phys. Rev. Lett. 79, 2586 (1997).  
4. D. S. Abrams, S. Lloyd, Phys. Rev. Lett. 83, 5162 (1999).  
5. A. Y. Kitaev, arXiv e-print; www.arxiv.org/abs/quant-ph/9511026 (1995).  
6. R. Cleve, A. Ekert, C. Macciavello, M. Mosca, Proc. R. Soc. London Ser. A 454, 313 (1998).  
7. L. Thogersen, J. Olsen, Chem. Phys. Lett. 393, 36 (2004).  
8. T. Helgaker, P. Jorgensen, J. Olsen, Molecular Electronic-Structure Theory (Wiley, Sussex, 2002).  
9. W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).  
10. M. Born, V. Fock, Zeit. Phys. 51, 165 (1928).  
11. E. Farhi, J. Goldstone, S. Gutmann, M. Sipser, arXiv e-print; www.arxiv.org/abs/quant-ph/0007071 (2000).  
12. E. Farhi et al., Science 292, 472 (2001).  
13. G. Ortiz, J. E. Gubernatis, E. Knill, R. Laflamme, Phys. Rev. A. 64, 022319 (2001).  
14. V. Bergholm, J. Vartainen, M. Mottonen, M. M. Salomaa, Phys. Rev. A. 71, 052330 (2005).  
15. This work was supported by a research grant from D-Wave systems.

# Supporting Online Material

www.sciencemag.org/cgi/content/full/309/5741/1704/DC1

Methods

References

12 April 2005; accepted 28 July 2005

10.1126/science.1113479

# Fe-Mg Interdiffusion in (Mg,Fe)SiO $_3$  Perovskite and Lower Mantle Reequilibration

Christian Holzapfel, $^{1*}$  David C. Rubie, $^{1}$  Daniel J. Frost, $^{1}$  Falko Langenhorst $^{2}$

Fe-Mg interdiffusion coefficients for  $(\mathrm{Mg},\mathrm{Fe})\mathrm{SiO}_3$  perovskite have been measured at pressures of 22 to 26 gigapascals and temperatures between 1973 and 2273 kelvin. Perovskite Fe-Mg interdiffusion is as slow as Si self-diffusion and is orders of magnitude slower than Fe-Mg diffusion in other mantle minerals. Length scales over which chemical heterogeneities can homogenize, throughout the depth range of the lower mantle, are limited to a few meters even on time scales equivalent to the age of Earth. Heterogeneities can therefore only equilibrate chemically when they are stretched and thinned by intense deformation.

The kinetics of many physical and chemical processes in Earth's mantle are controlled by solid-state diffusion (1-5). Thus, understanding and quantifying these processes in Earth requires knowledge of diffusion coefficients

for mantle minerals over the range of pressure-temperature conditions encompassed by Earth's mantle. The mineralogy of Earth's lower mantle is dominated by silicate perovskite  $(\sim 80$  volume  $\%$