"""
å·¥ä½œæµç¼–æ’å™¨ (Workflow Orchestrator)

è¯¥æ¨¡å—æ˜¯æ–°æ¶æ„çš„æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š
1. æ¥æ”¶åˆ†ç¦»åçš„æ•°æ®æºï¼ˆmain_papers, ref1_papers, ref2_papersï¼‰ã€‚
2. åˆå§‹åŒ–å¹¶è°ƒç”¨ä¸‰ä¸ªç‹¬ç«‹çš„å·¥ä½œæµï¼Œåˆ†åˆ«å¤„ç†ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚
3. æ”¶é›†æ¯ä¸ªå·¥ä½œæµçš„åˆ†æç»“æœã€‚
4. å°†æ•´åˆåçš„ç»“æœè¿”å›ç»™ä¸»æµç¨‹ï¼Œç”¨äºæœ€ç»ˆæŠ¥å‘Šçš„ç”Ÿæˆã€‚
"""
import os
import uuid
from pathlib import Path
from typing import List, Dict, Any

from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatTongyi

from . import config
from .final_analysis import FinalAnalyzer
from .workflows.workflow_contribution import ContributionWorkflow
from .workflows.workflow_field_problems import FieldProblemsWorkflow
from .workflows.workflow_undergrad_projects import UndergradProjectsWorkflow

class WorkflowOrchestrator:
    """
    è´Ÿè´£è°ƒåº¦å’Œæ‰§è¡Œæ‰€æœ‰åˆ†æå·¥ä½œæµçš„ä¸­å¿ƒæ§åˆ¶å™¨ã€‚
    """
    def __init__(self, professor_name: str, test_mode: bool):
        """
        åˆå§‹åŒ–æ‰€æœ‰LLMå®ä¾‹ã€å·¥ä½œæµä»¥åŠé…ç½®ã€‚
        """
        self._print_section_header("å­¦æœ¯å¼€ç›’demo - æ•´ä½“æµç¨‹", level=1)
        print("âš™ï¸  Initializing Workflow Orchestrator...")

        self.professor_name = professor_name
        self.test_mode = test_mode
        
        # 1. ç»Ÿä¸€åˆå§‹åŒ–LLMå®ä¾‹
        main_llm = ChatOpenAI(
            model=config.LLM_MODEL,
            openai_api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_API_BASE,
            temperature=config.LLM_TEMPERATURE
        )
        
        fallback_llm = None
        if config.DASHSCOPE_API_KEY:
            try:
                fallback_llm = ChatTongyi(
                    model=config.LLM_FALLBACK_MODEL,
                    dashscope_api_key=config.DASHSCOPE_API_KEY,
                    temperature=config.LLM_TEMPERATURE
                )
                print("  -> Fallback LLM (DashScope) initialized successfully.")
            except Exception as e:
                print(f"  âš ï¸ Could not initialize Fallback LLM. Reason: {e}")
                fallback_llm = None
        else:
            print("  -> INFO: Fallback LLM not configured. The program will run with the main LLM only.")

        # 2. å°†LLMå®ä¾‹æ³¨å…¥åˆ°å„ä¸ªå·¥ä½œæµä¸­
        self.contribution_workflow = ContributionWorkflow(main_llm, fallback_llm)
        self.field_problems_workflow = FieldProblemsWorkflow(main_llm, fallback_llm)
        self.undergrad_projects_workflow = UndergradProjectsWorkflow(main_llm, fallback_llm)
        
        # 3. åˆå§‹åŒ–æœ€ç»ˆåˆ†æå™¨ï¼Œå¹¶æ³¨å…¥LLMç”¨äºç¿»è¯‘
        self.final_analyzer = FinalAnalyzer(self.professor_name, main_llm)
        
        config.validate_config()
        print("âœ… Orchestrator initialized successfully.")

    def _print_section_header(self, title: str, level: int = 1):
        """æ‰“å°å¸¦æ ·å¼çš„ç« èŠ‚æ ‡é¢˜"""
        if level == 1:
            print(f"\n{'='*70}\nğŸ“ {title}\n{'='*70}")
        elif level == 2:
            print(f"\n--- {title} ---")

    def _load_papers_from_dir(self, dir_path: str, author: str, limit: int = 0) -> List[Dict[str, Any]]:
        """ä»æŒ‡å®šç›®å½•åŠ è½½æ‰€æœ‰è®ºæ–‡çš„å…ƒæ•°æ®ã€‚"""
        papers = []
        full_path = Path(dir_path)
        if not full_path.is_dir():
            print(f"    âš ï¸ Directory does not exist, skipping: {full_path}")
            return papers

        md_files = sorted(list(full_path.glob("*.md")))
        if limit > 0:
            md_files = md_files[:limit]

        for md_file in md_files:
            paper_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, md_file.stem))
            papers.append({
                "id": paper_id,
                "title": md_file.stem,
                "authors": [author],
                "md_filename": str(md_file),
            })
        return papers

    def run(self):
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼Œä»æ•°æ®åŠ è½½åˆ°æŠ¥å‘Šç”Ÿæˆã€‚
        """
        # æ­¥éª¤ 1: å‡†å¤‡å’Œåˆ†ç¦»æ•°æ®æº
        self._print_section_header("ä»»åŠ¡ä¸€ï¼šå‡†å¤‡å’Œåˆ†ç¦»è®ºæ–‡æ•°æ®æº", level=2)
        
        limit = config.TEST_MODE_PAPER_LIMIT if self.test_mode else 0
        base_data_path = Path(f"data/{self.professor_name}")
        
        # åŠ è½½æ•™æˆä»£è¡¨ä½œ (main) - å§‹ç»ˆå®Œæ•´åŠ è½½
        main_papers = self._load_papers_from_dir(str(base_data_path / "main"), self.professor_name)

        if self.test_mode:
            print(f"  -> è¿è¡Œåœ¨æµ‹è¯•æ¨¡å¼: æ•™æˆä»£è¡¨ä½œå°†å®Œæ•´åŠ è½½ ({len(main_papers)}ç¯‡) ä»¥ä¿è¯åˆ†æå‡†ç¡®æ€§ã€‚")
            print(f"  -> å…¶ä½™æ•°æ®æº (ref1, ref2) æœ€å¤šå¤„ç† {limit} ç¯‡è®ºæ–‡ã€‚")
            ref1_papers = self._load_papers_from_dir(str(base_data_path / "ref1"), "Various Authors", limit)
            ref2_papers = self._load_papers_from_dir(str(base_data_path / "ref2"), "Various Authors", limit)
        else:
            ref1_papers = self._load_papers_from_dir(str(base_data_path / "ref1"), "Various Authors")
            ref2_papers = self._load_papers_from_dir(str(base_data_path / "ref2"), "Various Authors")

        print("  -> æ•°æ®æºåˆ†ç¦»å®Œæˆ:")
        print(f"    - æ•™æˆä»£è¡¨ä½œ (main): {len(main_papers)} ç¯‡")
        print(f"    - å¼•ç”¨æ–‡çŒ® (ref1): {len(ref1_papers)} ç¯‡")
        print(f"    - æ½œåœ¨é¡¹ç›®æ–‡çŒ® (ref2): {len(ref2_papers)} ç¯‡")

        # æ­¥éª¤ 2: æ‰§è¡Œå„ä¸ªå·¥ä½œæµ
        self._print_section_header("ä»»åŠ¡äºŒï¼šæ‰§è¡Œåˆ†æå·¥ä½œæµ", level=2)
        all_results = {}

        # --- å·¥ä½œæµ1: åˆ†ææ•™æˆçš„æ ¸å¿ƒè´¡çŒ® ---
        print("\nâ¡ï¸ [Workflow 1/3] åˆ†ææ•™æˆçš„æ ¸å¿ƒè´¡çŒ®...")
        contribution_results = self.contribution_workflow.run(self.professor_name, main_papers)
        all_results['contribution_analysis'] = contribution_results

        # --- å·¥ä½œæµ2: åˆ†æé¢†åŸŸçš„çƒ­ç‚¹é—®é¢˜ ---
        print("\nâ¡ï¸ [Workflow 2/3] åˆ†æé¢†åŸŸçš„çƒ­ç‚¹é—®é¢˜...")
        field_problems_results = self.field_problems_workflow.run(
            main_papers=main_papers,
            ref1_papers=ref1_papers
        )
        all_results['field_problems_analysis'] = field_problems_results

        # --- å·¥ä½œæµ3: åˆ†ææœ¬ç§‘ç”Ÿå¯å‚ä¸çš„é¡¹ç›® ---
        print("\nâ¡ï¸ [Workflow 3/3] åˆ†ææœ¬ç§‘ç”Ÿå¯å‚ä¸çš„é¡¹ç›®...")
        # å°†å·¥ä½œæµ1çš„æ€»ç»“ä½œä¸ºè¾“å…¥ï¼Œä¼ é€’ç»™å·¥ä½œæµ3
        contribution_summary = contribution_results.get("summary", "")
        undergrad_projects_results = self.undergrad_projects_workflow.run(
            self.professor_name, 
            ref2_papers,
            contribution_summary
        )
        all_results['undergrad_projects_analysis'] = undergrad_projects_results

        print("\n--- æ‰€æœ‰å·¥ä½œæµæ‰§è¡Œå®Œæ¯• ---\n")

        # æ­¥éª¤ 3: æ•´åˆç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._print_section_header("ä»»åŠ¡ä¸‰ï¼šæ•´åˆç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š", level=2)
        english_report = self.final_analyzer.generate_final_report(all_results)

        # æ­¥éª¤ 4: å°†æŠ¥å‘Šç¿»è¯‘ä¸ºä¸­æ–‡
        self._print_section_header("ä»»åŠ¡å››ï¼šç¿»è¯‘æŠ¥å‘Šä¸ºä¸­æ–‡", level=2)
        chinese_report = self.final_analyzer.translate_report(english_report, "Chinese")

        # æ­¥éª¤ 5: ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        report_filename = config.OUTPUT_DIR / f"{self.professor_name}_final_report.md"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(chinese_report)
        print(f"\nâœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")

        self._print_section_header("å­¦æœ¯å¼€ç›’å®Œæˆ", level=1)
