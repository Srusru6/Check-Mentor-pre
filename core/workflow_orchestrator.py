"""
å·¥ä½œæµç¼–æ’å™¨ (Workflow Orchestrator)

è¯¥æ¨¡å—æ˜¯æ–°æ¶æ„çš„æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š
1. æ¥æ”¶åˆ†ç¦»åçš„æ•°æ®æºï¼ˆmain_papers, ref1_papers, cited_papersï¼‰ã€‚
2. åˆå§‹åŒ–å¹¶è°ƒç”¨ä¸‰ä¸ªç‹¬ç«‹çš„å·¥ä½œæµï¼Œåˆ†åˆ«å¤„ç†ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚
3. æ”¶é›†æ¯ä¸ªå·¥ä½œæµçš„åˆ†æç»“æœã€‚
4. å°†æ•´åˆåçš„ç»“æœè¿”å›ç»™ä¸»æµç¨‹ï¼Œç”¨äºæœ€ç»ˆæŠ¥å‘Šçš„ç”Ÿæˆã€‚
"""
import os
import uuid
import json
from pathlib import Path
from typing import List, Dict, Any, Optional

from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatTongyi

from . import config
from .final_analysis import FinalAnalyzer
from .metadata_manager import MetadataManager
from .workflows.workflow_contribution import ContributionWorkflow
from .workflows.workflow_field_problems import FieldProblemsWorkflow
from .workflows.workflow_undergrad_projects import UndergradProjectsWorkflow

def prepare_workflow_inputs(test_mode: bool, limit: int,
                            main_papers: List[Dict[str, Any]],
                            ref1_papers: List[Dict[str, Any]],
                            cited_papers: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """æ ¹æ®æ–°è§„åˆ™ä¸ test_modeï¼Œå‡†å¤‡ä¸‰æ¡å·¥ä½œæµçš„è¾“å…¥ã€‚

    å‡è®¾ main/ref1/cited å·²æŒ‰å…ƒæ•°æ®æ—¶åºæ’åºï¼ˆæ–°â†’æ—§ï¼‰ã€‚
    """
    if test_mode:
        return {
            # Workflow 1: mainï¼ˆä¸æˆªæ–­ï¼‰
            "wf1_main": main_papers,
            # Workflow 2: main å‰N + cited å‰Nï¼ˆæ—  ref1ï¼‰
            "wf2_main": main_papers[:limit],
            "wf2_ref1": [],
            "wf2_cited": cited_papers[:limit],
            # Workflow 3: ä»… cited å‰N
            "wf3_main": [],
            "wf3_cited": cited_papers[:limit],
        }
    else:
        return {
            "wf1_main": main_papers,
            "wf2_main": main_papers,
            "wf2_ref1": ref1_papers,
            "wf2_cited": cited_papers,
            "wf3_main": main_papers,
            "wf3_cited": cited_papers,
        }

class WorkflowOrchestrator:
    """
    è´Ÿè´£è°ƒåº¦å’Œæ‰§è¡Œæ‰€æœ‰åˆ†æå·¥ä½œæµçš„ä¸­å¿ƒæ§åˆ¶å™¨ã€‚
    """
    def __init__(self, professor_name: str, test_mode: bool, data_root: Optional[str | Path] = None):
        """
        åˆå§‹åŒ–æ‰€æœ‰LLMå®ä¾‹ã€å·¥ä½œæµä»¥åŠé…ç½®ã€‚
        """
        self._print_section_header("å­¦æœ¯å¼€ç›’demo - æ•´ä½“æµç¨‹", level=1)
        print("âš™ï¸  Initializing Workflow Orchestrator...")
        
        self.professor_name = professor_name
        self.test_mode = test_mode
        # å…è®¸å¤–éƒ¨æŒ‡å®šæ•°æ®æ ¹ç›®å½•ï¼ˆåº”ç›´æ¥æŒ‡å‘åŒ…å« main/ref1/ref2 çš„ç›®å½•ï¼‰ï¼Œ
        # é»˜è®¤ä»ä¸º data/{professor_name}
        self.data_root = Path(data_root) if data_root else Path(f"data/{self.professor_name}")
        
        # 1. ç»Ÿä¸€åˆå§‹åŒ–LLMå®ä¾‹
        main_llm = ChatOpenAI(
            model=config.LLM_MODEL,
            openai_api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_API_BASE,
            temperature=config.LLM_TEMPERATURE
        )
        
        fallback_llm = None
        if config.DASHSCOPE_API_KEY:
            try:
                fallback_llm = ChatTongyi(
                    model=config.LLM_FALLBACK_MODEL,
                    dashscope_api_key=config.DASHSCOPE_API_KEY,
                    temperature=config.LLM_TEMPERATURE
                )
                print("  -> Fallback LLM (DashScope) initialized successfully.")
            except Exception as e:
                print(f"  âš ï¸ Could not initialize Fallback LLM. Reason: {e}")
                fallback_llm = None
        else:
            print("  -> INFO: Fallback LLM not configured. The program will run with the main LLM only.")

        # 2. å°†LLMå®ä¾‹æ³¨å…¥åˆ°å„ä¸ªå·¥ä½œæµä¸­
        self.contribution_workflow = ContributionWorkflow(main_llm, fallback_llm)
        self.field_problems_workflow = FieldProblemsWorkflow(main_llm, fallback_llm)
        # ä¼ é€’æµ‹è¯•æ¨¡å¼æ ‡å¿—ï¼Œä»¥ä¾¿åœ¨æµ‹è¯•æ¨¡å¼ä¸‹è¿›è¡Œæ›´ç¨³å¥çš„å›é€€å¤„ç†
        self.undergrad_projects_workflow = UndergradProjectsWorkflow(main_llm, fallback_llm, test_mode=self.test_mode)
        
        # 3. åˆå§‹åŒ–æœ€ç»ˆåˆ†æå™¨ï¼Œå¹¶æ³¨å…¥LLMç”¨äºç¿»è¯‘
        self.final_analyzer = FinalAnalyzer(self.professor_name, main_llm)
        
        # 4. åˆå§‹åŒ–å…ƒæ•°æ®ç®¡ç†å™¨
        self.metadata_manager = MetadataManager()
        
        config.validate_config()
        print("âœ… Orchestrator initialized successfully.")

    def _print_section_header(self, title: str, level: int = 1):
        """æ‰“å°å¸¦æ ·å¼çš„ç« èŠ‚æ ‡é¢˜"""
        if level == 1:
            print(f"\n{'='*70}\nğŸ“ {title}\n{'='*70}")
        elif level == 2:
            print(f"\n--- {title} ---")

    def _load_papers_from_dir(self, dir_path: str, author: str, limit: int = 0) -> List[Dict[str, Any]]:
        """ä»æŒ‡å®šç›®å½•åŠ è½½æ‰€æœ‰è®ºæ–‡çš„å…ƒæ•°æ®ã€‚"""
        papers = []
        full_path = Path(dir_path)
        if not full_path.is_dir():
            print(f"    âš ï¸ Directory does not exist, skipping: {full_path}")
            return papers

        md_files = sorted(list(full_path.glob("*.md")))
        if limit > 0:
            md_files = md_files[:limit]

        for md_file in md_files:
            paper_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, md_file.stem))
            papers.append({
                "id": paper_id,
                "title": md_file.stem,
                "authors": [author],
                "md_filename": str(md_file),
            })
        return papers
    
    def _load_metadata_for_directory(self, dir_path: Path) -> bool:
        """
        ä¸ºæŒ‡å®šç›®å½•åŠ è½½å…ƒæ•°æ®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        
        å…ƒæ•°æ®æ–‡ä»¶åº”å‘½åä¸º 'metadata.json' æˆ– 'history.json' å¹¶ä½äºè®ºæ–‡ç›®å½•ä¸­
        
        Args:
            dir_path: è®ºæ–‡ç›®å½•è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½å…ƒæ•°æ®
        """
        # ä¼˜å…ˆå°è¯• history.jsonï¼ˆæ–°æ ¼å¼ï¼‰
        history_file = dir_path / "history.json"
        if history_file.exists():
            print(f"    ğŸ“‹ å‘ç°å…ƒæ•°æ®æ–‡ä»¶: {history_file.name}")
            return self.metadata_manager.load_metadata_file(history_file)
        
        # å›é€€åˆ° metadata.jsonï¼ˆæ—§æ ¼å¼ï¼‰
        metadata_file = dir_path / "metadata.json"
        if metadata_file.exists():
            print(f"    ğŸ“‹ å‘ç°å…ƒæ•°æ®æ–‡ä»¶: {metadata_file.name}")
            return self.metadata_manager.load_metadata_file(metadata_file)
        
        print(f"    â„¹ï¸  æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ (history.json æˆ– metadata.json)")
        return False

    def run(self):
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼Œä»æ•°æ®åŠ è½½åˆ°æŠ¥å‘Šç”Ÿæˆã€‚
        """
        # æ­¥éª¤ 1: å‡†å¤‡å’Œåˆ†ç¦»æ•°æ®æº
        self._print_section_header("ä»»åŠ¡ä¸€ï¼šå‡†å¤‡å’Œåˆ†ç¦»è®ºæ–‡æ•°æ®æº", level=2)
        
        limit = config.TEST_MODE_PAPER_LIMIT if self.test_mode else 0
        base_data_path = self.data_root
        
        # å°è¯•åŠ è½½å„ä¸ªç›®å½•çš„å…ƒæ•°æ®
        print("\nğŸ” æ£€æŸ¥å¹¶åŠ è½½å…ƒæ•°æ®æ–‡ä»¶...")
        main_path = base_data_path / "main"
        ref1_path = base_data_path / "ref1"
        cited_path = base_data_path / "cited"
        # å‘åå…¼å®¹ï¼šè‹¥æ–°ç›®å½•ä¸å­˜åœ¨ä½†æ—§ç›®å½•å­˜åœ¨ï¼Œåˆ™å›é€€åˆ°æ—§ç›®å½•
        legacy_ref2_path = base_data_path / "ref2"
        if not cited_path.exists() and legacy_ref2_path.exists():
            print("  âš ï¸  å…¼å®¹æ¨¡å¼ï¼šæœªæ‰¾åˆ° 'cited' ç›®å½•ï¼Œæ£€æµ‹åˆ°æ—§ç›®å½• 'ref2'ï¼Œå°†ä¸´æ—¶ä½¿ç”¨ 'ref2'ã€‚è¯·å°½å¿«è¿ç§»æ•°æ®åˆ° 'cited/'.")
            cited_path = legacy_ref2_path
        
        print(f"  [Main] {main_path}")
        self._load_metadata_for_directory(main_path)
        
        print(f"  [Ref1] {ref1_path}")
        self._load_metadata_for_directory(ref1_path)
        
        print(f"  [Cited] {cited_path}")
        self._load_metadata_for_directory(cited_path)
        
        # æ‰“å°å…ƒæ•°æ®ç»Ÿè®¡
        if len(self.metadata_manager.metadata_cache) > 0:
            self.metadata_manager.print_statistics()
        else:
            print("    â„¹ï¸  æœªåŠ è½½ä»»ä½•å…ƒæ•°æ®ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        
        # åŠ è½½è®ºæ–‡ - åŠ è½½é˜¶æ®µä¸åšæˆªæ–­ï¼Œç»Ÿä¸€ç”±åç»­â€œå·²æŒ‰æ—¶åºæ’åºâ€çš„é˜¶æ®µæŒ‰è§„åˆ™æˆªæ–­
        main_papers = self._load_papers_from_dir(str(main_path), self.professor_name)
        ref1_papers = self._load_papers_from_dir(str(ref1_path), "Various Authors")
        cited_papers = self._load_papers_from_dir(str(cited_path), "Various Authors")
        
        # ä¸ºè®ºæ–‡æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
        print("\nğŸ“ ä¸ºè®ºæ–‡æ·»åŠ å…ƒæ•°æ®...")
        main_papers = self.metadata_manager.get_papers_with_metadata(main_papers)
        ref1_papers = self.metadata_manager.get_papers_with_metadata(ref1_papers)
        cited_papers = self.metadata_manager.get_papers_with_metadata(cited_papers)
        
        # æŒ‰å‘å¸ƒæ—¶é—´å¯¹è®ºæ–‡è¿›è¡Œæ’åºï¼ˆæ›´æ–°çš„è®ºæ–‡åœ¨å‰ï¼‰ï¼Œä¸ºåç»­â€œå…ˆæ—¶åºã€å†å–å‰Nâ€åšå‡†å¤‡
        if len(self.metadata_manager.metadata_cache) > 0:
            print("  âœ“ æŒ‰å‘å¸ƒæ—¶é—´å¯¹è®ºæ–‡è¿›è¡Œæ’åºï¼ˆæ–°â†’æ—§ï¼‰...")
            main_papers = self.metadata_manager.sort_papers_by_recency(main_papers, descending=True)
            ref1_papers = self.metadata_manager.sort_papers_by_recency(ref1_papers, descending=True)
            cited_papers = self.metadata_manager.sort_papers_by_recency(cited_papers, descending=True)

        print("  -> æ•°æ®æºåˆ†ç¦»å®Œæˆ:")
        print(f"    - æ•™æˆä»£è¡¨ä½œ (main): {len(main_papers)} ç¯‡")
        print(f"    - å¼•ç”¨æ–‡çŒ® (ref1): {len(ref1_papers)} ç¯‡")
        print(f"    - æ½œåœ¨é¡¹ç›®æ–‡çŒ® (cited): {len(cited_papers)} ç¯‡")

        # åŸºäºæ–°è§„åˆ™ï¼Œå‡†å¤‡å„å·¥ä½œæµçš„è¾“å…¥ï¼ˆåœ¨å·²æ’åºçš„åˆ—è¡¨ä¸Šå†åšæˆªæ–­ï¼‰
        limit = config.TEST_MODE_PAPER_LIMIT
        prepared = prepare_workflow_inputs(self.test_mode, limit, main_papers, ref1_papers, cited_papers)
        if self.test_mode:
            print(f"  -> æµ‹è¯•æ¨¡å¼å¯ç”¨ï¼šç¬¬äºŒå·¥ä½œæµä½¿ç”¨ main/cited å„å‰{limit}ç¯‡ï¼›ç¬¬ä¸‰å·¥ä½œæµä½¿ç”¨ cited å‰{limit}ç¯‡ã€‚")
        wf1_main = prepared["wf1_main"]
        wf2_main = prepared["wf2_main"]
        wf2_ref1 = prepared["wf2_ref1"]
        wf2_cited = prepared["wf2_cited"]
        wf3_main = prepared["wf3_main"]
        wf3_cited = prepared["wf3_cited"]

        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = "log"
        os.makedirs(log_dir, exist_ok=True)

        def log_workflow_output(workflow_name: str, data: Any):
            """å°†å·¥ä½œæµçš„è¾“å‡ºç»“æœä»¥JSONæ ¼å¼è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶ã€‚"""
            log_path = os.path.join(log_dir, f"{self.professor_name}_{workflow_name}_output.json")
            try:
                with open(log_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                # print(f"    -> Logged {workflow_name} output to {log_path}")
            except Exception as e:
                print(f"    âš ï¸ Failed to log {workflow_name} output. Reason: {e}")

        # æ­¥éª¤ 2: æ‰§è¡Œå„ä¸ªå·¥ä½œæµ
        self._print_section_header("ä»»åŠ¡äºŒï¼šæ‰§è¡Œåˆ†æå·¥ä½œæµ", level=2)
        all_results = {}

        # --- å·¥ä½œæµ1: åˆ†ææ•™æˆçš„æ ¸å¿ƒè´¡çŒ® ---
        print("\nâ¡ï¸ [Workflow 1/3] åˆ†ææ•™æˆçš„æ ¸å¿ƒè´¡çŒ®...")
        contribution_results = self.contribution_workflow.run(self.professor_name, wf1_main)
        log_workflow_output("contribution", contribution_results)
        all_results['contribution_analysis'] = contribution_results

        # --- å·¥ä½œæµ2: åˆ†æé¢†åŸŸçš„çƒ­ç‚¹é—®é¢˜ ---
        print("\nâ¡ï¸ [Workflow 2/3] åˆ†æé¢†åŸŸçš„çƒ­ç‚¹é—®é¢˜...")
        field_problems_results = self.field_problems_workflow.run(
            professor_name=self.professor_name,
            main_papers=wf2_main,
            ref1_papers=wf2_ref1,
            cited_papers=wf2_cited,
        )
        log_workflow_output("field_problems", field_problems_results)
        all_results['field_problems_analysis'] = field_problems_results

        # --- å·¥ä½œæµ3: åˆ†ææœ¬ç§‘ç”Ÿå¯å‚ä¸çš„é¡¹ç›® ---
        print("\nâ¡ï¸ [Workflow 3/3] åˆ†ææœ¬ç§‘ç”Ÿå¯å‚ä¸çš„é¡¹ç›®...")
        # å°†å·¥ä½œæµ1çš„æ€»ç»“ä½œä¸ºè¾“å…¥ï¼Œä¼ é€’ç»™å·¥ä½œæµ3
        contribution_summary = contribution_results.get("contribution_summary", "")
        undergrad_projects_results = self.undergrad_projects_workflow.run(
            self.professor_name,
            wf3_main,
            wf3_cited,
            contribution_summary,
        )
        log_workflow_output("undergrad_projects", undergrad_projects_results)
        all_results['undergrad_projects_analysis'] = undergrad_projects_results

        print("\n--- æ‰€æœ‰å·¥ä½œæµæ‰§è¡Œå®Œæ¯• ---\n")

        # æ­¥éª¤ 3: æ•´åˆç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._print_section_header("ä»»åŠ¡ä¸‰ï¼šæ•´åˆç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š", level=2)
        english_report = self.final_analyzer.generate_final_report(all_results)

        # æ­¥éª¤ 4: å°†æŠ¥å‘Šç¿»è¯‘ä¸ºä¸­æ–‡
        self._print_section_header("ä»»åŠ¡å››ï¼šç¿»è¯‘æŠ¥å‘Šä¸ºä¸­æ–‡", level=2)
        chinese_report = self.final_analyzer.translate_report(english_report, "Chinese")

        # æ­¥éª¤ 5: ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        report_filename = config.OUTPUT_DIR / f"{self.professor_name}_final_report.md"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(chinese_report)
        print(f"\nâœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")

        self._print_section_header("å­¦æœ¯å¼€ç›’å®Œæˆ", level=1)
