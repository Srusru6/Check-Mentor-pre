"""
å·¥ä½œæµç¼–æ’å™¨ (Workflow Orchestrator)

è¯¥æ¨¡å—æ˜¯æ–°æ¶æ„çš„æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š
1. æ¥æ”¶åˆ†ç¦»åçš„æ•°æ®æºï¼ˆmain_papers, ref1_papers, ref2_papersï¼‰ã€‚
2. åˆå§‹åŒ–å¹¶è°ƒç”¨ä¸‰ä¸ªç‹¬ç«‹çš„å·¥ä½œæµï¼Œåˆ†åˆ«å¤„ç†ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚
3. æ”¶é›†æ¯ä¸ªå·¥ä½œæµçš„åˆ†æç»“æœã€‚
4. å°†æ•´åˆåçš„ç»“æœè¿”å›ç»™ä¸»æµç¨‹ï¼Œç”¨äºæœ€ç»ˆæŠ¥å‘Šçš„ç”Ÿæˆã€‚
"""
import os
import uuid
import json
from pathlib import Path
from typing import List, Dict, Any

from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatTongyi

from . import config
from .final_analysis import FinalAnalyzer
from .metadata_manager import MetadataManager
from .workflows.workflow_contribution import ContributionWorkflow
from .workflows.workflow_field_problems import FieldProblemsWorkflow
from .workflows.workflow_undergrad_projects import UndergradProjectsWorkflow

class WorkflowOrchestrator:
    """
    è´Ÿè´£è°ƒåº¦å’Œæ‰§è¡Œæ‰€æœ‰åˆ†æå·¥ä½œæµçš„ä¸­å¿ƒæ§åˆ¶å™¨ã€‚
    """
    def __init__(self, professor_name: str, test_mode: bool):
        """
        åˆå§‹åŒ–æ‰€æœ‰LLMå®ä¾‹ã€å·¥ä½œæµä»¥åŠé…ç½®ã€‚
        """
        self._print_section_header("å­¦æœ¯å¼€ç›’demo - æ•´ä½“æµç¨‹", level=1)
        print("âš™ï¸  Initializing Workflow Orchestrator...")

        self.professor_name = professor_name
        self.test_mode = test_mode
        
        # 1. ç»Ÿä¸€åˆå§‹åŒ–LLMå®ä¾‹
        main_llm = ChatOpenAI(
            model=config.LLM_MODEL,
            openai_api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_API_BASE,
            temperature=config.LLM_TEMPERATURE
        )
        
        fallback_llm = None
        if config.DASHSCOPE_API_KEY:
            try:
                fallback_llm = ChatTongyi(
                    model=config.LLM_FALLBACK_MODEL,
                    dashscope_api_key=config.DASHSCOPE_API_KEY,
                    temperature=config.LLM_TEMPERATURE
                )
                print("  -> Fallback LLM (DashScope) initialized successfully.")
            except Exception as e:
                print(f"  âš ï¸ Could not initialize Fallback LLM. Reason: {e}")
                fallback_llm = None
        else:
            print("  -> INFO: Fallback LLM not configured. The program will run with the main LLM only.")

        # 2. å°†LLMå®ä¾‹æ³¨å…¥åˆ°å„ä¸ªå·¥ä½œæµä¸­
        self.contribution_workflow = ContributionWorkflow(main_llm, fallback_llm)
        self.field_problems_workflow = FieldProblemsWorkflow(main_llm, fallback_llm)
        self.undergrad_projects_workflow = UndergradProjectsWorkflow(main_llm, fallback_llm)
        
        # 3. åˆå§‹åŒ–æœ€ç»ˆåˆ†æå™¨ï¼Œå¹¶æ³¨å…¥LLMç”¨äºç¿»è¯‘
        self.final_analyzer = FinalAnalyzer(self.professor_name, main_llm)
        
        # 4. åˆå§‹åŒ–å…ƒæ•°æ®ç®¡ç†å™¨
        self.metadata_manager = MetadataManager()
        
        config.validate_config()
        print("âœ… Orchestrator initialized successfully.")

    def _print_section_header(self, title: str, level: int = 1):
        """æ‰“å°å¸¦æ ·å¼çš„ç« èŠ‚æ ‡é¢˜"""
        if level == 1:
            print(f"\n{'='*70}\nğŸ“ {title}\n{'='*70}")
        elif level == 2:
            print(f"\n--- {title} ---")

    def _load_papers_from_dir(self, dir_path: str, author: str, limit: int = 0) -> List[Dict[str, Any]]:
        """ä»æŒ‡å®šç›®å½•åŠ è½½æ‰€æœ‰è®ºæ–‡çš„å…ƒæ•°æ®ã€‚"""
        papers = []
        full_path = Path(dir_path)
        if not full_path.is_dir():
            print(f"    âš ï¸ Directory does not exist, skipping: {full_path}")
            return papers

        md_files = sorted(list(full_path.glob("*.md")))
        if limit > 0:
            md_files = md_files[:limit]

        for md_file in md_files:
            paper_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, md_file.stem))
            papers.append({
                "id": paper_id,
                "title": md_file.stem,
                "authors": [author],
                "md_filename": str(md_file),
            })
        return papers
    
    def _load_metadata_for_directory(self, dir_path: Path) -> bool:
        """
        ä¸ºæŒ‡å®šç›®å½•åŠ è½½å…ƒæ•°æ®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        
        å…ƒæ•°æ®æ–‡ä»¶åº”å‘½åä¸º 'metadata.json' å¹¶ä½äºè®ºæ–‡ç›®å½•ä¸­
        
        Args:
            dir_path: è®ºæ–‡ç›®å½•è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½å…ƒæ•°æ®
        """
        metadata_file = dir_path / "metadata.json"
        if metadata_file.exists():
            print(f"    ğŸ“‹ å‘ç°å…ƒæ•°æ®æ–‡ä»¶: {metadata_file.name}")
            return self.metadata_manager.load_metadata_file(metadata_file)
        else:
            print(f"    â„¹ï¸  æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ (metadata.json)")
            return False

    def run(self):
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼Œä»æ•°æ®åŠ è½½åˆ°æŠ¥å‘Šç”Ÿæˆã€‚
        """
        # æ­¥éª¤ 1: å‡†å¤‡å’Œåˆ†ç¦»æ•°æ®æº
        self._print_section_header("ä»»åŠ¡ä¸€ï¼šå‡†å¤‡å’Œåˆ†ç¦»è®ºæ–‡æ•°æ®æº", level=2)
        
        limit = config.TEST_MODE_PAPER_LIMIT if self.test_mode else 0
        base_data_path = Path(f"data/{self.professor_name}")
        
        # å°è¯•åŠ è½½å„ä¸ªç›®å½•çš„å…ƒæ•°æ®
        print("\nğŸ” æ£€æŸ¥å¹¶åŠ è½½å…ƒæ•°æ®æ–‡ä»¶...")
        main_path = base_data_path / "main"
        ref1_path = base_data_path / "ref1"
        ref2_path = base_data_path / "ref2"
        
        print(f"  [Main] {main_path}")
        self._load_metadata_for_directory(main_path)
        
        print(f"  [Ref1] {ref1_path}")
        self._load_metadata_for_directory(ref1_path)
        
        print(f"  [Ref2] {ref2_path}")
        self._load_metadata_for_directory(ref2_path)
        
        # æ‰“å°å…ƒæ•°æ®ç»Ÿè®¡
        if len(self.metadata_manager.metadata_cache) > 0:
            self.metadata_manager.print_statistics()
        else:
            print("    â„¹ï¸  æœªåŠ è½½ä»»ä½•å…ƒæ•°æ®ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        
        # åŠ è½½æ•™æˆä»£è¡¨ä½œ (main) - å§‹ç»ˆå®Œæ•´åŠ è½½
        main_papers = self._load_papers_from_dir(str(main_path), self.professor_name)

        if self.test_mode:
            print(f"  -> è¿è¡Œåœ¨æµ‹è¯•æ¨¡å¼: æ•™æˆä»£è¡¨ä½œå°†å®Œæ•´åŠ è½½ ({len(main_papers)}ç¯‡) ä»¥ä¿è¯åˆ†æå‡†ç¡®æ€§ã€‚")
            print(f"  -> å…¶ä½™æ•°æ®æº (ref1, ref2) æœ€å¤šå¤„ç† {limit} ç¯‡è®ºæ–‡ã€‚")
            ref1_papers = self._load_papers_from_dir(str(ref1_path), "Various Authors", limit)
            ref2_papers = self._load_papers_from_dir(str(ref2_path), "Various Authors", limit)
        else:
            ref1_papers = self._load_papers_from_dir(str(ref1_path), "Various Authors")
            ref2_papers = self._load_papers_from_dir(str(ref2_path), "Various Authors")
        
        # ä¸ºè®ºæ–‡æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
        print("\nğŸ“ ä¸ºè®ºæ–‡æ·»åŠ å…ƒæ•°æ®...")
        main_papers = self.metadata_manager.get_papers_with_metadata(main_papers)
        ref1_papers = self.metadata_manager.get_papers_with_metadata(ref1_papers)
        ref2_papers = self.metadata_manager.get_papers_with_metadata(ref2_papers)
        
        # æŒ‰å‘å¸ƒæ—¶é—´å¯¹è®ºæ–‡è¿›è¡Œæ’åºï¼ˆæ›´æ–°çš„è®ºæ–‡åœ¨å‰ï¼‰
        if len(self.metadata_manager.metadata_cache) > 0:
            print("  âœ“ æŒ‰å‘å¸ƒæ—¶é—´å¯¹è®ºæ–‡è¿›è¡Œæ’åºï¼ˆæ–°â†’æ—§ï¼‰...")
            main_papers = self.metadata_manager.sort_papers_by_recency(main_papers, descending=True)
            ref1_papers = self.metadata_manager.sort_papers_by_recency(ref1_papers, descending=True)
            ref2_papers = self.metadata_manager.sort_papers_by_recency(ref2_papers, descending=True)

        print("  -> æ•°æ®æºåˆ†ç¦»å®Œæˆ:")
        print(f"    - æ•™æˆä»£è¡¨ä½œ (main): {len(main_papers)} ç¯‡")
        print(f"    - å¼•ç”¨æ–‡çŒ® (ref1): {len(ref1_papers)} ç¯‡")
        print(f"    - æ½œåœ¨é¡¹ç›®æ–‡çŒ® (ref2): {len(ref2_papers)} ç¯‡")

        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = "log"
        os.makedirs(log_dir, exist_ok=True)

        def log_workflow_output(workflow_name: str, data: Any):
            """å°†å·¥ä½œæµçš„è¾“å‡ºç»“æœä»¥JSONæ ¼å¼è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶ã€‚"""
            log_path = os.path.join(log_dir, f"{self.professor_name}_{workflow_name}_output.json")
            try:
                with open(log_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                # print(f"    -> Logged {workflow_name} output to {log_path}")
            except Exception as e:
                print(f"    âš ï¸ Failed to log {workflow_name} output. Reason: {e}")

        # æ­¥éª¤ 2: æ‰§è¡Œå„ä¸ªå·¥ä½œæµ
        self._print_section_header("ä»»åŠ¡äºŒï¼šæ‰§è¡Œåˆ†æå·¥ä½œæµ", level=2)
        all_results = {}

        # --- å·¥ä½œæµ1: åˆ†ææ•™æˆçš„æ ¸å¿ƒè´¡çŒ® ---
        print("\nâ¡ï¸ [Workflow 1/3] åˆ†ææ•™æˆçš„æ ¸å¿ƒè´¡çŒ®...")
        contribution_results = self.contribution_workflow.run(self.professor_name, main_papers)
        log_workflow_output("contribution", contribution_results)
        all_results['contribution_analysis'] = contribution_results

        # --- å·¥ä½œæµ2: åˆ†æé¢†åŸŸçš„çƒ­ç‚¹é—®é¢˜ ---
        print("\nâ¡ï¸ [Workflow 2/3] åˆ†æé¢†åŸŸçš„çƒ­ç‚¹é—®é¢˜...")
        field_problems_results = self.field_problems_workflow.run(
            professor_name=self.professor_name,
            main_papers=main_papers,
            ref1_papers=ref1_papers
        )
        log_workflow_output("field_problems", field_problems_results)
        all_results['field_problems_analysis'] = field_problems_results

        # --- å·¥ä½œæµ3: åˆ†ææœ¬ç§‘ç”Ÿå¯å‚ä¸çš„é¡¹ç›® ---
        print("\nâ¡ï¸ [Workflow 3/3] åˆ†ææœ¬ç§‘ç”Ÿå¯å‚ä¸çš„é¡¹ç›®...")
        # å°†å·¥ä½œæµ1çš„æ€»ç»“ä½œä¸ºè¾“å…¥ï¼Œä¼ é€’ç»™å·¥ä½œæµ3
        contribution_summary = contribution_results.get("contribution_summary", "")
        undergrad_projects_results = self.undergrad_projects_workflow.run(
            self.professor_name, 
            ref2_papers,
            contribution_summary
        )
        log_workflow_output("undergrad_projects", undergrad_projects_results)
        all_results['undergrad_projects_analysis'] = undergrad_projects_results

        print("\n--- æ‰€æœ‰å·¥ä½œæµæ‰§è¡Œå®Œæ¯• ---\n")

        # æ­¥éª¤ 3: æ•´åˆç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._print_section_header("ä»»åŠ¡ä¸‰ï¼šæ•´åˆç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š", level=2)
        english_report = self.final_analyzer.generate_final_report(all_results)

        # æ­¥éª¤ 4: å°†æŠ¥å‘Šç¿»è¯‘ä¸ºä¸­æ–‡
        self._print_section_header("ä»»åŠ¡å››ï¼šç¿»è¯‘æŠ¥å‘Šä¸ºä¸­æ–‡", level=2)
        chinese_report = self.final_analyzer.translate_report(english_report, "Chinese")

        # æ­¥éª¤ 5: ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        report_filename = config.OUTPUT_DIR / f"{self.professor_name}_final_report.md"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(chinese_report)
        print(f"\nâœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")

        self._print_section_header("å­¦æœ¯å¼€ç›’å®Œæˆ", level=1)
